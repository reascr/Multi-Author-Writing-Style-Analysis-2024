{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"fe50ce5ff6a944659b08ca80c703f861":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_e12a2512f72f40f09802d91d81e0ccd5","IPY_MODEL_9fcbe4d55b35416da3ebbd779825e011","IPY_MODEL_42c2e91157924462a355ef6ec31e26b2","IPY_MODEL_5f5289f4b56845b9bb03117ef3fa16fc"],"layout":"IPY_MODEL_86a51298208241229daaccf838638655"}},"aad2418a00da4f819ff1bed76490c051":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0a133ba0f634f9990c1e206a9b5b554","placeholder":"​","style":"IPY_MODEL_2b823eb3be044155a117f6f3d46b11e9","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"ef6d362a25974a25b542680b57f3b60f":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_e6ce08f4fc8c494280e4353362179921","placeholder":"​","style":"IPY_MODEL_1ff3079f442c44068f995d98d61377ea","value":""}},"00564ade2d464fd69878d6d2f5ede645":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_8c7dbfac987e4aa187a420bfbe73c43d","style":"IPY_MODEL_e8f7c7bfae874f30927ed223ea5a44be","value":true}},"a900098837f74861a603c28395bf1749":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_5bbe5211a8ef47fa84d22741fc2d967b","style":"IPY_MODEL_76ea783da0d4458a946e5130b92b96d0","tooltip":""}},"c86559985df4454e8b8bd32778592899":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ec852db0a4b4d6392fb7d475713a12c","placeholder":"​","style":"IPY_MODEL_b60aee7584944536837b12e77ca9e527","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"86a51298208241229daaccf838638655":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"e0a133ba0f634f9990c1e206a9b5b554":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b823eb3be044155a117f6f3d46b11e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6ce08f4fc8c494280e4353362179921":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ff3079f442c44068f995d98d61377ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c7dbfac987e4aa187a420bfbe73c43d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8f7c7bfae874f30927ed223ea5a44be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5bbe5211a8ef47fa84d22741fc2d967b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76ea783da0d4458a946e5130b92b96d0":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"2ec852db0a4b4d6392fb7d475713a12c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b60aee7584944536837b12e77ca9e527":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b01599cbae1e4570bab8419a474b3fb5":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1eb03e774a1e47e7899bb286fdd0799c","placeholder":"​","style":"IPY_MODEL_c48cd608f6f64b5e97e91f93b46fd3a1","value":"Connecting..."}},"1eb03e774a1e47e7899bb286fdd0799c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c48cd608f6f64b5e97e91f93b46fd3a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e12a2512f72f40f09802d91d81e0ccd5":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ecbc093d7214fedb527b0f6f13c53e8","placeholder":"​","style":"IPY_MODEL_bf80433aa6aa4a158d09716da0969065","value":"Token is valid (permission: write)."}},"9fcbe4d55b35416da3ebbd779825e011":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a53384304134b9fb64bb157182c1352","placeholder":"​","style":"IPY_MODEL_087917e16f1244c293a7a679140c8b80","value":"Your token has been saved in your configured git credential helpers (store)."}},"42c2e91157924462a355ef6ec31e26b2":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_049df87d0ec649bc8f6892a2e9a42a89","placeholder":"​","style":"IPY_MODEL_911452bab5ab40e7940bcae4dbcfd45c","value":"Your token has been saved to /root/.cache/huggingface/token"}},"5f5289f4b56845b9bb03117ef3fa16fc":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b4334fa52d6429bb7e5316b7323b658","placeholder":"​","style":"IPY_MODEL_0d5b966b44b546fcba76ad55f17b26f9","value":"Login successful"}},"7ecbc093d7214fedb527b0f6f13c53e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf80433aa6aa4a158d09716da0969065":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a53384304134b9fb64bb157182c1352":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"087917e16f1244c293a7a679140c8b80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"049df87d0ec649bc8f6892a2e9a42a89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"911452bab5ab40e7940bcae4dbcfd45c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b4334fa52d6429bb7e5316b7323b658":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d5b966b44b546fcba76ad55f17b26f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["This code was created following the tutorial: [hugging face - fine tune mistral](https://huggingface.co/blog/sirluk/multilabel-llm)"],"metadata":{"id":"7nTQTvMRWOcK"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8QMWjU2klfM3","outputId":"e56f2c08-efde-4f71-d029-5d970d43efcf","executionInfo":{"status":"ok","timestamp":1714473023439,"user_tz":-120,"elapsed":180943,"user":{"displayName":"Ronja Stern","userId":"13352545349885877164"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scikit-multilearn\n","  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scikit-multilearn\n","Successfully installed scikit-multilearn-0.2.0\n","Collecting datasets\n","  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Collecting huggingface-hub>=0.21.2 (from datasets)\n","  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.20.3\n","    Uninstalling huggingface-hub-0.20.3:\n","      Successfully uninstalled huggingface-hub-0.20.3\n","Successfully installed datasets-2.19.0 dill-0.3.8 huggingface-hub-0.22.2 multiprocess-0.70.16 xxhash-3.4.1\n","Collecting peft\n","  Downloading peft-0.10.0-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.2.1+cu121)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.40.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.2)\n","Collecting accelerate>=0.21.0 (from peft)\n","  Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.3)\n","Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.22.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.13.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.0->peft)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.0->peft)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.0->peft)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13.0->peft)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.0->peft)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.0->peft)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->peft)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->peft)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.0->peft)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.13.0->peft)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.0->peft)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate, peft\n","Successfully installed accelerate-0.29.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 peft-0.10.0\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.2.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.127)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","Installing collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.43.1\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.29.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.22.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Collecting wandb\n","  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-2.0.1-py2.py3-none-any.whl (266 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.8/266.8 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n","Collecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.43 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-2.0.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.6\n"]}],"source":["!pip install scikit-multilearn\n","!pip install datasets\n","!pip install peft\n","!pip install bitsandbytes\n","!pip install accelerate\n","!pip install wandb"]},{"cell_type":"code","source":["exit()"],"metadata":{"id":"WBsA0nLnOope","executionInfo":{"status":"ok","timestamp":1714473023439,"user_tz":-120,"elapsed":24,"user":{"displayName":"Ronja Stern","userId":"13352545349885877164"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import os\n","import random\n","import functools\n","import csv\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn.functional as F\n","from sklearn.metrics import f1_score\n","from skmultilearn.model_selection import iterative_train_test_split\n","from datasets import Dataset, DatasetDict\n","from peft import (\n","    LoraConfig,\n","    prepare_model_for_kbit_training,\n","    get_peft_model\n",")\n","from transformers import (\n","    AutoModelForSequenceClassification,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    TrainingArguments,\n","    Trainer\n",")"],"metadata":{"id":"qRMOQ9LbG6mo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714473300157,"user_tz":-120,"elapsed":8952,"user":{"displayName":"Ronja Stern","userId":"13352545349885877164"}},"outputId":"79927a7a-423c-4a12-d1c3-98ce2bae572a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:bitsandbytes.cextension:The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"]}]},{"cell_type":"code","source":["import wandb\n","wandb.login()\n","\n","# let's log every trained\n","# %env WANDB_LOG_MODEL=true\n","\n","wandb_project_name = \"LLP2-test\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"id":"Wit5iIwNXEI5","outputId":"660b1562-f6f5-4e18-ed36-20715ec64a0f","executionInfo":{"status":"ok","timestamp":1714473096528,"user_tz":-120,"elapsed":33924,"user":{"displayName":"Ronja Stern","userId":"13352545349885877164"}}},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}]},{"cell_type":"code","source":["\n","from huggingface_hub import notebook_login\n","\n","notebook_login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["fe50ce5ff6a944659b08ca80c703f861","aad2418a00da4f819ff1bed76490c051","ef6d362a25974a25b542680b57f3b60f","00564ade2d464fd69878d6d2f5ede645","a900098837f74861a603c28395bf1749","c86559985df4454e8b8bd32778592899","86a51298208241229daaccf838638655","e0a133ba0f634f9990c1e206a9b5b554","2b823eb3be044155a117f6f3d46b11e9","e6ce08f4fc8c494280e4353362179921","1ff3079f442c44068f995d98d61377ea","8c7dbfac987e4aa187a420bfbe73c43d","e8f7c7bfae874f30927ed223ea5a44be","5bbe5211a8ef47fa84d22741fc2d967b","76ea783da0d4458a946e5130b92b96d0","2ec852db0a4b4d6392fb7d475713a12c","b60aee7584944536837b12e77ca9e527","b01599cbae1e4570bab8419a474b3fb5","1eb03e774a1e47e7899bb286fdd0799c","c48cd608f6f64b5e97e91f93b46fd3a1","e12a2512f72f40f09802d91d81e0ccd5","9fcbe4d55b35416da3ebbd779825e011","42c2e91157924462a355ef6ec31e26b2","5f5289f4b56845b9bb03117ef3fa16fc","7ecbc093d7214fedb527b0f6f13c53e8","bf80433aa6aa4a158d09716da0969065","0a53384304134b9fb64bb157182c1352","087917e16f1244c293a7a679140c8b80","049df87d0ec649bc8f6892a2e9a42a89","911452bab5ab40e7940bcae4dbcfd45c","6b4334fa52d6429bb7e5316b7323b658","0d5b966b44b546fcba76ad55f17b26f9"]},"id":"yXtKcULnMSu-","outputId":"d0c0a599-a29e-4a6d-8f5d-6106296fdf1b","executionInfo":{"status":"ok","timestamp":1714473126508,"user_tz":-120,"elapsed":668,"user":{"displayName":"Ronja Stern","userId":"13352545349885877164"}}},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe50ce5ff6a944659b08ca80c703f861"}},"metadata":{}}]},{"cell_type":"code","source":["# Method and Model Configuration\n","entity = \"rstern\"\n","retrain_from_checkpoint = False\n","model_config = \"frozen_model_1\" # possible values: no_freezing_model, frozen_model_1, frozen_model_2\n","author_label_only = True\n","augmented_data = True\n","experiment_name = \"full_aug_b\"\n","debugg = True"],"metadata":{"id":"ZDCh65USXoxl","executionInfo":{"status":"ok","timestamp":1714473307909,"user_tz":-120,"elapsed":272,"user":{"displayName":"Ronja Stern","userId":"13352545349885877164"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Load Dataset"],"metadata":{"id":"CmFM2hwmxtJc"}},{"cell_type":"code","source":["try:\n","  import google.colab\n","  IN_COLAB = True\n","except:\n","  IN_COLAB = False\n","if IN_COLAB:\n","  from google.colab import drive\n","  import sys\n","  drive.mount('/content/drive')\n","  # sys.path.append('/content/drive/MyDrive/ucph/LP Project') # If working in collab change this path\n","  path = '/content/drive/MyDrive/ucph/LP Project/'\n","  if augmented_data:\n","    train_df = pd.read_csv(f'{path}balanced_train.csv')\n","    val_df = pd.read_csv(f'{path}balanced_val.csv')\n","  else:\n","    train_df = pd.read_csv(f'{path}df_train.csv')\n","    val_df = pd.read_csv(f'{path}df_validation.csv')\n","\n","# shuffle dataset\n","train_df = train_df.sample(frac=1, random_state=42)\n","val_df = val_df.sample(frac=1, random_state=42)\n","print(train_df.sample(5))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uV7nFJyCxxFp","outputId":"96ab81a9-0a9f-470f-fe4d-4332fa0dc36b","executionInfo":{"status":"ok","timestamp":1714473315233,"user_tz":-120,"elapsed":6107,"user":{"displayName":"Ronja Stern","userId":"13352545349885877164"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","        Unnamed: 0                                         paragraph1  \\\n","8176          8176  I agree. At this point there’s no way to bring...   \n","76779        76779  When death is the punishment for peaceful acti...   \n","7208          7208  \"In an article for the Columbia Journalism Rev...   \n","123796      123796  Fun fact! The purchase, possession, and consum...   \n","93840        93840  My question is this: How is it possible to cas...   \n","\n","                                               paragraph2  label_author  \\\n","8176    r/politics is currently accepting new moderato...             1   \n","76779   Once they start imprisoning or executing the f...             1   \n","7208    This has dramatically increased American influ...             1   \n","123796  i am for legalization and i have enjoyed weed ...             0   \n","93840   That's the thing. If we were to just give up, ...             1   \n","\n","        label_dataset  fileindex  \n","8176                0       3121  \n","76779               2       1095  \n","7208                0       2738  \n","123796              1       3071  \n","93840               2       3406  \n"]}]},{"cell_type":"code","source":["print(train_df.columns)\n","\n","def create_sequences(row):\n","  sequence = str(row[\"paragraph1\"]) + \"[LP2]\" + str(row[\"paragraph2\"])\n","  return sequence\n","\n","train_df[\"input\"] = train_df.apply(create_sequences, axis=1)\n","val_df[\"input\"] = val_df.apply(create_sequences, axis=1)\n","\n","x_train = train_df[\"input\"].values\n","x_val = val_df[\"input\"].values\n","\n","def create_multilabel(row):\n","  label_dataset = max(min(1, row[\"label_dataset\"]), 0)\n","  multilabel = np.array([int(row[\"label_author\"]), int(label_dataset)])\n","  return multilabel\n","\n","def create_singlelabel(row):\n","  label = np.array([int(row[\"label_author\"])])\n","  return label\n","\n","if author_label_only:\n","  train_df[\"label\"] = train_df.apply(create_singlelabel, axis=1)\n","  val_df[\"label\"] = val_df.apply(create_singlelabel, axis=1)\n","  label_weights = [1]\n","else:\n","  train_df[\"label\"] = train_df.apply(create_multilabel, axis=1)\n","  val_df[\"label\"] = val_df.apply(create_multilabel, axis=1)\n","  # weight author label heavier than topic change label\n","  label_weights = [2,1]\n","\n","y_train = train_df[\"label\"].values\n","y_train = np.stack(y_train)\n","y_val = val_df[\"label\"].values\n","y_val = np.stack(y_val)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ToqHix1C0_5i","outputId":"02b8e5a2-e626-40b8-c41b-1575ca66b50a","executionInfo":{"status":"ok","timestamp":1714473332673,"user_tz":-120,"elapsed":5729,"user":{"displayName":"Ronja Stern","userId":"13352545349885877164"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['Unnamed: 0', 'paragraph1', 'paragraph2', 'label_author',\n","       'label_dataset', 'fileindex'],\n","      dtype='object')\n"]}]},{"cell_type":"code","source":["print(x_train.shape, y_train.shape, y_train[0])\n","print(x_train[0])\n","print(x_val.shape, y_val.shape, y_val[0])\n","print(x_val[0])"],"metadata":{"id":"JXezq1F_4FCh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714473335699,"user_tz":-120,"elapsed":293,"user":{"displayName":"Ronja Stern","userId":"13352545349885877164"}},"outputId":"a1ae177b-9728-4ed0-9e6f-a4e6570563ba"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["(125600,) (125600, 1) [1]\n","In 2020 the polling suggested that Trump and Biden would have a tight race (which they did, sort of) but also that the Democratic party would pick up something like five seats in the Senate and win a clear majority, instead we saw Republicans voting for Biden at the top of the ticket and voting for Republicans at the bottom of the ticket, and the Senate ended up with a 50/50 tie.[LP2]Hi! I actually just voted for Warnock about an hour ago. . My question: to what degree do you think the current statewide political landscape is directly attributable to Donald Trump turning off so many moderate Republican voters? I do not understand how the state went from having uniform Republican control statewide to having Senators like Warnock and Ossoff in such a short amount of time.\n","(28262,) (28262, 1) [0]\n","Well, I don't know much about accreditation to be fair, but federal grants come from a lot more places than just DOEd, and many of those sponsors have already included language requiring certain diversity and equity activities and expect there to be offices at IHEs that would address diversity concerns across campus. If those offices are shuttered, grants from NSF and other agencies may be in jeopardy for Florida IHEs.[LP2]They probably will if these types of things actually pass and start being enforced. Their universities can say goodbye to most federal grants as well if these laws are actually implemented.\n"]}]},{"cell_type":"code","source":["x_train_sub = x_train[0:50]\n","y_train_sub = y_train[0:50]\n","x_val_sub = x_val[0:50]\n","y_val_sub = y_val[0:50]\n"],"metadata":{"id":"h0U404tbbBBH","executionInfo":{"status":"ok","timestamp":1714473340772,"user_tz":-120,"elapsed":254,"user":{"displayName":"Ronja Stern","userId":"13352545349885877164"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["if debugg:\n","  ds = DatasetDict({\n","    'train': Dataset.from_dict({'text': x_train_sub, 'labels': y_train_sub}),\n","    'val': Dataset.from_dict({'text': x_val_sub, 'labels': y_val_sub})\n","  })\n","else:\n","  ds = DatasetDict({\n","      'train': Dataset.from_dict({'text': x_train, 'labels': y_train}),\n","      'val': Dataset.from_dict({'text': x_val, 'labels': y_val})\n","  })\n"],"metadata":{"id":"NiAqJfN_ID9F","executionInfo":{"status":"ok","timestamp":1714473364968,"user_tz":-120,"elapsed":251,"user":{"displayName":"Ronja Stern","userId":"13352545349885877164"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["Load the model"],"metadata":{"id":"YiGnZz7GLnVG"}},{"cell_type":"code","source":["# model name\n","model_name = 'mistralai/Mistral-7B-v0.1'\n","\n","# qunatization config\n","quantization_config = BitsAndBytesConfig(\n","    load_in_4bit = True, # enable 4-bit quantization\n","    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n","    bnb_4bit_use_double_quant = True, # quantize quantized weights //insert xzibit meme\n","    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n",")\n","\n","# lora config\n","lora_config = LoraConfig(\n","    r = 16, # the dimension of the low-rank matrices\n","    lora_alpha = 8, # scaling factor for LoRA activations vs pre-trained weight activations\n","    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n","    lora_dropout = 0.05, # dropout probability of the LoRA layers\n","    bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n","    task_type = 'SEQ_CLS'\n",")\n","\n","#### FREEZING FUCNTIONS\n","def freeze_all_but_last(model):\n","  for param in model.parameters():\n","    param.requires_grad = False  # Freeze all parameters\n","  for param in model.classifier.parameters():\n","    param.requires_grad = True   # Unfreeze only the last layer (classifier)\n","\n","def freeze_specific_layers(model, layer_names_to_unfreeze):\n","  for name, param in model.named_parameters():\n","    if any(layer_name in name for layer_name in layer_names_to_unfreeze):\n","      param.requires_grad = True  # Unfreeze specified layers\n","    else:\n","      param.requires_grad = False  # Freeze other parameters\n","\n","# preprocess dataset with tokenizer\n","def tokenize_examples(examples, tokenizer):\n","    tokenized_inputs = tokenizer(examples['text'])\n","    tokenized_inputs['labels'] = examples['labels']\n","    return tokenized_inputs\n"],"metadata":{"id":"O0aUzB3lLpJK","executionInfo":{"status":"ok","timestamp":1714473369968,"user_tz":-120,"elapsed":286,"user":{"displayName":"Ronja Stern","userId":"13352545349885877164"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","#####\n","# new tokens\n","new_tokens = [\"[LP2]\"]\n","\n","# check if the tokens are already in the vocabulary\n","new_tokens = set(new_tokens) - set(tokenizer.vocab.keys())\n","\n","# add the tokens to the tokenizer vocabulary\n","tokenizer.add_tokens(list(new_tokens))\n","\n","# add new, random embeddings for the new tokens\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenized_ds = ds.map(functools.partial(tokenize_examples, tokenizer=tokenizer), batched=True)\n","tokenized_ds = tokenized_ds.with_format('torch')\n","\n","# Experiment 0: no freezing\n","no_freezing_model = AutoModelForSequenceClassification.from_pretrained(\n","    model_name,\n","    quantization_config=quantization_config,\n","    num_labels=y_train.shape[1]\n",")\n","no_freezing_model = prepare_model_for_kbit_training(no_freezing_model)\n","no_freezing_model = get_peft_model(no_freezing_model, lora_config)\n","no_freezing_model.config.pad_token_id = tokenizer.pad_token_id\n","no_freezing_model.resize_token_embeddings(len(tokenizer))\n","\n","# Experiment 1: Freeze all except last layer\n","frozen_model_1 = AutoModelForSequenceClassification.from_pretrained(\n","    model_name, num_labels=y_train.shape[1])\n","freeze_all_but_last(frozen_model_1)\n","frozen_model_1 = prepare_model_for_kbit_training(frozen_model_1)\n","frozen_model_1 = get_peft_model(frozen_model_1, lora_config)\n","frozen_model_1.config.pad_token_id = tokenizer.pad_token_id\n","frozen_model_1.resize_token_embeddings(len(tokenizer))\n","\n","# Experiment 2: Freeze all except specific layers (replace with your desired layers)\n","frozen_model_2 = AutoModelForSequenceClassification.from_pretrained(\n","    model_name, num_labels=y_train.shape[1])\n","freeze_specific_layers(frozen_model_2, [\"encoder.layer.12\"])  # Example: Unfreeze only layer 12\n","frozen_model_2 = prepare_model_for_kbit_training(frozen_model_2)\n","frozen_model_2 = get_peft_model(frozen_model_2, lora_config)\n","frozen_model_2.config.pad_token_id = tokenizer.pad_token_id\n","frozen_model_2.resize_token_embeddings(len(tokenizer))\n","\n"],"metadata":{"id":"RoOl0ivJHEMe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_dict = {\"no_freezing_model\":no_freezing_model, \"frozen_model_1\": frozen_model_1, \"frozen_model_2\": frozen_model_2}"],"metadata":{"id":"jKRraFjMvuQ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define if you retrain from local checkpoint or want to train from scratch\n","if retrain_from_checkpoint:\n","  model = model.from_pretrained(f'multilabel_classification/{model_name}')\n","else:\n","  model = model_dict[model_config]\n"],"metadata":{"id":"bH2anO69tF2r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define custom batch preprocessor\n","def collate_fn(batch, tokenizer):\n","    dict_keys = ['input_ids', 'attention_mask', 'labels']\n","    d = {k: [dic[k] for dic in batch] for k in dict_keys}\n","    d['input_ids'] = torch.nn.utils.rnn.pad_sequence(\n","        d['input_ids'], batch_first=True, padding_value=tokenizer.pad_token_id\n","    )\n","    d['attention_mask'] = torch.nn.utils.rnn.pad_sequence(\n","        d['attention_mask'], batch_first=True, padding_value=0\n","    )\n","    d['labels'] = torch.stack(d['labels'])\n","    return d\n","\n","# define which metrics to compute for evaluation\n","def compute_metrics(p):\n","    predictions, labels = p\n","    f1_micro = f1_score(labels, predictions > 0, average = 'micro')\n","    f1_macro = f1_score(labels, predictions > 0, average = 'macro')\n","    f1_weighted = f1_score(labels, predictions > 0, average = 'weighted')\n","    return {\n","        'f1_micro': f1_micro,\n","        'f1_macro': f1_macro,\n","        'f1_weighted': f1_weighted\n","    }\n","\n","\n","# create custom trainer class to be able to pass label weights and calculate multilabel loss\n","class CustomTrainer(Trainer):\n","\n","    def __init__(self, label_weights, **kwargs):\n","        super().__init__(**kwargs)\n","        self.label_weights = label_weights\n","\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        labels = inputs.pop(\"labels\")\n","\n","        # forward pass\n","        outputs = model(**inputs)\n","        logits = outputs.get(\"logits\")\n","\n","        # compute custom loss\n","        loss = F.binary_cross_entropy_with_logits(logits, labels.to(torch.float32), pos_weight=self.label_weights)\n","        return (loss, outputs) if return_outputs else loss\n","\n","\n","def print_trainable_parameters(model):\n","    \"\"\"\n","    Prints the number of trainable parameters in the model.\n","    \"\"\"\n","    trainable_params = 0\n","    all_param = 0\n","    for _, param in model.named_parameters():\n","        all_param += param.numel()\n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","    print(\n","        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n","    )\n","\n","\n","# Define training function with freezing strategies\n","def train_and_evaluate(model, model_name, frozen=False):\n","    wandb.init(entity=entity, project=\"lp2\", name=experiment_name)  # Update name with model name\n","\n","    # define training args with potentially different learning rates for frozen models\n","    training_args = TrainingArguments(\n","        output_dir=f'multilabel_classification/{model_name}',  # Separate output directory\n","        learning_rate=1e-5 if frozen else 1e-4,  # Adjust learning rate for frozen models (optional)\n","        per_device_train_batch_size=8,\n","        per_device_eval_batch_size=8,\n","        num_train_epochs=10,\n","        weight_decay=0.01,\n","        evaluation_strategy='epoch',\n","        save_strategy='steps',  # Save based on steps\n","        save_steps=25,\n","        load_best_model_at_end=True,\n","        logging_steps=25,              # When to start reporting loss\n","        logging_dir=f\"./logs/{model_name}\",  # Separate log directory\n","        save_steps=25,                # Save checkpoints every 50 steps\n","        report_to=[\"wandb\"],\n","    )\n","\n","    # train\n","    trainer = CustomTrainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=tokenized_ds['train'],\n","        eval_dataset=tokenized_ds['val'],\n","        tokenizer=tokenizer,\n","        data_collator=functools.partial(collate_fn, tokenizer=tokenizer),\n","        compute_metrics=compute_metrics,\n","        label_weights=torch.tensor(label_weights, device=model.device)\n","      )\n","\n","    trainer.train()\n","\n","    # save model and tokenizer separately\n","    model_save_path = f\"multilabel_mistral_{model_name}\"\n","    trainer.model.save_pretrained(model_save_path)\n","    tokenizer.save_pretrained(model_save_path)\n","\n","    print(f\"Model and tokenizer saved to {model_save_path}\")\n","\n"],"metadata":{"id":"bB349j18x4pz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Train the original model (without freezing)\n","print_trainable_parameters(model)\n","train_and_evaluate(model, model_config)  # Pass model name for wandb\n"],"metadata":{"id":"hhqWVcjS4AN7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save model local and on the hub if training was successfull.\n","test_results = trainer.evaluate(tokenized_ds['val'])\n","print(test_results)\n","trainer.save_model()\n","trainer.save_state()\n","trainer.push_to_hub()"],"metadata":{"id":"Qb228nlk15LM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Train model with frozen last layer only\n","\"\"\"\n","frozen_model_1 = AutoModelForSequenceClassification.from_pretrained(\n","    frozen_model_1, num_labels=y_train.shape[1])\n","freeze_all_but_last(frozen_model_1)\n","print_trainable_parameters(frozen_model_1)\n","train_and_evaluate(frozen_model_1, model_config)\n","\"\"\""],"metadata":{"id":"6BgtyFvJ4BIf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Train model with specific layer unfrozen (replace 12 with your desired layer)\n","\"\"\"frozen_model_2 = AutoModelForSequenceClassification.from_pretrained(\n","    frozen_model_2, num_labels=y_train.shape[1])\n","freeze_specific_layers(frozen_model_2, [\"encoder.layer.12\"])  # Example: Unfreeze only layer 12\n","print_trainable_parameters(frozen_model_2)\n","train_and_evaluate(frozen_model_2, model_config)\n","\"\"\""],"metadata":{"id":"JKiqa6um4B50"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # define training args\n","# training_args = TrainingArguments(\n","#     output_dir = 'multilabel_classification',\n","#     learning_rate = 1e-4,\n","#     per_device_train_batch_size = 8,\n","#     per_device_eval_batch_size = 8,\n","#     num_train_epochs = 10,\n","#     weight_decay = 0.01,\n","#     evaluation_strategy = 'epoch',\n","#     save_strategy = 'epoch',\n","#     load_best_model_at_end = True,\n","#     logging_steps=25,              # When to start reporting loss\n","#     logging_dir=\"./logs\",        # Directory for storing logs\n","#     save_steps=25,                # Save checkpoints every 50 steps\n","#     report_to = [\"wandb\"],\n","# )\n","\n","# # train\n","# trainer = CustomTrainer(\n","#     model = model,\n","#     args = training_args,\n","#     train_dataset = tokenized_ds['train'],\n","#     eval_dataset = tokenized_ds['val'],\n","#     tokenizer = tokenizer,\n","#     data_collator = functools.partial(collate_fn, tokenizer=tokenizer),\n","#     compute_metrics = compute_metrics,\n","#     label_weights = torch.tensor(label_weights, device=model.device)\n","# )\n","\n","# trainer.train()\n","\n","# # save model\n","# peft_model_id = 'multilabel_mistral'\n","# trainer.model.save_pretrained(peft_model_id)\n","# tokenizer.save_pretrained(peft_model_id)"],"metadata":{"id":"oOpYXxuYU3ix"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load model\n","# peft_model_id = 'multilabel_mistral'\n","# model = AutoModelForSequenceClassification.from_pretrained(peft_model_id)"],"metadata":{"id":"23n1icJcWIZS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["wandb.finish()"],"metadata":{"id":"NbNSXXFHZ8Uh"},"execution_count":null,"outputs":[]}]}