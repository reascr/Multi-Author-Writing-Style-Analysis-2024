{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8439640,"sourceType":"datasetVersion","datasetId":5027447}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Baseline using a simple CountVectorizer","metadata":{}},{"cell_type":"code","source":"import os, json\nimport pandas as pd\nimport numpy as np\n#!pip install --upgrade tensorflow\nimport tensorflow as tf\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import CountVectorizer","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:43:27.477835Z","iopub.execute_input":"2024-05-17T11:43:27.478972Z","iopub.status.idle":"2024-05-17T11:43:27.484279Z","shell.execute_reply.started":"2024-05-17T11:43:27.478914Z","shell.execute_reply":"2024-05-17T11:43:27.483275Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# running locally\n'''BASE_DIR = '../data_pipeline/'\n\n# get data sets \ndf_train = pd.read_csv(os.path.join(BASE_DIR, \"df_train.csv\"), index_col=0)\ndf_val = pd.read_csv(os.path.join(BASE_DIR, \"df_validation.csv\"), index_col=0)\n\ntotal_data = len(df_train) + len(df_val)\ntrain_ratio = len(df_train) / total_data\nval_ratio = len(df_val) / total_data\n\nprint(f\"Train-Val split is: {train_ratio:.2f}-{val_ratio:.2f}\")\n# split val 0.5:0.5 in val and test\n\ndf_val, df_test = train_test_split(df_val, test_size=0.5, random_state=42)\n\ndf_test.head()'''","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:37:52.266708Z","iopub.execute_input":"2024-05-17T11:37:52.267240Z","iopub.status.idle":"2024-05-17T11:37:52.274580Z","shell.execute_reply.started":"2024-05-17T11:37:52.267213Z","shell.execute_reply":"2024-05-17T11:37:52.273531Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'BASE_DIR = \\'../data_pipeline/\\'\\n\\n# get data sets \\ndf_train = pd.read_csv(os.path.join(BASE_DIR, \"df_train.csv\"), index_col=0)\\ndf_val = pd.read_csv(os.path.join(BASE_DIR, \"df_validation.csv\"), index_col=0)\\n\\ntotal_data = len(df_train) + len(df_val)\\ntrain_ratio = len(df_train) / total_data\\nval_ratio = len(df_val) / total_data\\n\\nprint(f\"Train-Val split is: {train_ratio:.2f}-{val_ratio:.2f}\")\\n# split val 0.5:0.5 in val and test\\n\\ndf_val, df_test = train_test_split(df_val, test_size=0.5, random_state=42)\\n\\ndf_test.head()'"},"metadata":{}}]},{"cell_type":"code","source":"# running in kaggle\n\ndf_train = pd.read_csv('/kaggle/input/author-data/df_train.csv')\ndf_val = pd.read_csv('/kaggle/input/author-data/df_validation.csv')\n\ndf_val, df_test = train_test_split(df_val, test_size=0.5, random_state=42)\ndf_test.head()\n\n# REPLACE WITH ACTUAL TEST SET!","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:43:31.025030Z","iopub.execute_input":"2024-05-17T11:43:31.025719Z","iopub.status.idle":"2024-05-17T11:43:31.551634Z","shell.execute_reply.started":"2024-05-17T11:43:31.025684Z","shell.execute_reply":"2024-05-17T11:43:31.550672Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"      Unnamed: 0                                         paragraph1  \\\n3532        3532  In general, be courteous to others. Debate/dis...   \n2899        2899  A paper airplane powered by a nuclear powered ...   \n3822        3822  Once they have the enriched uranium it is surp...   \n5846        5846  If it’s not political, being a leftist is irre...   \n9035        9035  Irrelevant, if confirmed it would mean there w...   \n\n                                             paragraph2  label_author  \\\n3532  For those who have questions regarding any med...             0   \n2899  Do I get to mark \"Turns out USA created Corona...             1   \n3822  Its a combination of materials and secrets. Nu...             1   \n5846  Yes it is. Of course, if you enacted a policy ...             0   \n9035  This time, it looks like it wasn't Russia so i...             1   \n\n      label_dataset  n_authors  fileindex  \n3532              1          2        205  \n2899              1          2         80  \n3822              1          4        266  \n5846              1          4        662  \n9035              2          4        427  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>paragraph1</th>\n      <th>paragraph2</th>\n      <th>label_author</th>\n      <th>label_dataset</th>\n      <th>n_authors</th>\n      <th>fileindex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3532</th>\n      <td>3532</td>\n      <td>In general, be courteous to others. Debate/dis...</td>\n      <td>For those who have questions regarding any med...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>205</td>\n    </tr>\n    <tr>\n      <th>2899</th>\n      <td>2899</td>\n      <td>A paper airplane powered by a nuclear powered ...</td>\n      <td>Do I get to mark \"Turns out USA created Corona...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>3822</th>\n      <td>3822</td>\n      <td>Once they have the enriched uranium it is surp...</td>\n      <td>Its a combination of materials and secrets. Nu...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>266</td>\n    </tr>\n    <tr>\n      <th>5846</th>\n      <td>5846</td>\n      <td>If it’s not political, being a leftist is irre...</td>\n      <td>Yes it is. Of course, if you enacted a policy ...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>662</td>\n    </tr>\n    <tr>\n      <th>9035</th>\n      <td>9035</td>\n      <td>Irrelevant, if confirmed it would mean there w...</td>\n      <td>This time, it looks like it wasn't Russia so i...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>4</td>\n      <td>427</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# convert labels to numerical values\nlabel_encoder = LabelEncoder()\ny_train = label_encoder.fit_transform(df_train['label_author'])\ny_val = label_encoder.transform(df_val['label_author'])\ny_test = label_encoder.transform(df_test['label_author'])\n\n# get bow representation of paragraph1\nvectorizer_par1 = CountVectorizer(max_features=5000)\nX_train_par1 = vectorizer_par1.fit_transform(df_train['paragraph1']).toarray()\nX_val_par1 = vectorizer_par1.transform(df_val['paragraph1']).toarray()\nX_test_par1 = vectorizer_par1.transform(df_test['paragraph1']).toarray()\n\n# get bow representation of paragraph2\nvectorizer_par2 = CountVectorizer(max_features=5000)\nX_train_par2 = vectorizer_par2.fit_transform(df_train['paragraph2']).toarray()\nX_val_par2 = vectorizer_par2.transform(df_val['paragraph2']).toarray()\nX_test_par2 = vectorizer_par2.transform(df_test['paragraph2']).toarray()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:43:35.000977Z","iopub.execute_input":"2024-05-17T11:43:35.001908Z","iopub.status.idle":"2024-05-17T11:43:45.138254Z","shell.execute_reply.started":"2024-05-17T11:43:35.001867Z","shell.execute_reply":"2024-05-17T11:43:45.137173Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"done\ndone\ndone\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the features for training, validation, and test  sets\nX_train = np.concatenate((X_train_par1, X_train_par2), axis=1)\nX_val = np.concatenate((X_val_par1, X_val_par2), axis=1)\nX_test = np.concatenate((X_test_par1, X_test_par2), axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:43:56.732405Z","iopub.execute_input":"2024-05-17T11:43:56.733076Z","iopub.status.idle":"2024-05-17T11:43:58.562148Z","shell.execute_reply.started":"2024-05-17T11:43:56.733045Z","shell.execute_reply":"2024-05-17T11:43:58.561019Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nhistory = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n\n# evaluate on validation set\nval_loss, val_accuracy = model.evaluate(X_val, y_val)\nprint(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n\n# evaluate on test set REPLACE WITH ACTUAL TEST SET\ntest_loss, test_accuracy = model.evaluate(X_test, y_test)\nprint(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')","metadata":{"execution":{"iopub.status.busy":"2024-05-17T11:44:17.696992Z","iopub.execute_input":"2024-05-17T11:44:17.697669Z","iopub.status.idle":"2024-05-17T11:45:23.116034Z","shell.execute_reply.started":"2024-05-17T11:44:17.697637Z","shell.execute_reply":"2024-05-17T11:45:23.114910Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n\u001b[1m  56/1625\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6017 - loss: 0.6411","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1715946270.560979     316 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1715946270.576967     316 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1625/1625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6610 - loss: 0.5594","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1715946276.838447     314 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1625/1625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.6610 - loss: 0.5594 - val_accuracy: 0.6603 - val_loss: 0.5364\nEpoch 2/10\n\u001b[1m1625/1625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7582 - loss: 0.4502 - val_accuracy: 0.6549 - val_loss: 0.5712\nEpoch 3/10\n\u001b[1m1625/1625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9045 - loss: 0.2302 - val_accuracy: 0.6508 - val_loss: 0.8332\nEpoch 4/10\n\u001b[1m1625/1625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9856 - loss: 0.0567 - val_accuracy: 0.6535 - val_loss: 1.4251\nEpoch 5/10\n\u001b[1m1625/1625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0190 - val_accuracy: 0.6428 - val_loss: 1.6908\nEpoch 6/10\n\u001b[1m1625/1625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0097 - val_accuracy: 0.6457 - val_loss: 2.0608\nEpoch 7/10\n\u001b[1m1625/1625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0133 - val_accuracy: 0.6494 - val_loss: 2.1097\nEpoch 8/10\n\u001b[1m1625/1625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0084 - val_accuracy: 0.6487 - val_loss: 2.3388\nEpoch 9/10\n\u001b[1m1625/1625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0048 - val_accuracy: 0.6424 - val_loss: 2.4327\nEpoch 10/10\n\u001b[1m1625/1625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0066 - val_accuracy: 0.6437 - val_loss: 2.4029\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6375 - loss: 2.4654\nValidation Loss: 2.4028570652008057, Validation Accuracy: 0.6436863541603088\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6636 - loss: 2.2192\nTest Loss: 2.2304365634918213, Test Accuracy: 0.6651187539100647\n","output_type":"stream"}]}]}