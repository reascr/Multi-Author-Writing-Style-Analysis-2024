{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91792d21-48e7-48c5-bf4e-4433d1226037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import functools\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import f1_score\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import DatasetDict, Dataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "from peft import PeftModel, PeftConfig\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model\n",
    ")\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5df8e13b-d1d3-4681-b772-8b4c1333e384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrstern\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/amin/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/amin/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"6f9fce3d2b3e41f8880b3e0b094e16ec9d030315\")\n",
    "from huggingface_hub import notebook_login, login\n",
    "#notebook_login()\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3af97245-4971-483c-803c-ce6e45848e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method and Model Configuration\n",
    "# ---------------------------------------------------------\n",
    "entity = \"rstern\"\n",
    "debugg = False\n",
    "model_name = 'filipealmeida/Mistral-7B-v0.1-sharded'\n",
    "# ---------------------------------------------------------\n",
    "# emb_org_a, emb_org_b, emb_aug_a, emb_aug_b\n",
    "experiment_name = \"emb_org_b\" # model ## augmented_data ## author_label_only\n",
    "augmented_data = False # True: aug, False: org\n",
    "author_label_only = False # False: b and True: a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d684e32-4abe-4b0c-b6f0-cf7cfc4c2efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_0 = pd.read_csv('test_df_0.csv')\n",
    "test_df_1 = pd.read_csv('test_df_1.csv')\n",
    "test_df_2 = pd.read_csv('test_df_2.csv')\n",
    "\n",
    "# shuffle dataset\n",
    "test_df_0 = test_df_0.sample(frac=1, random_state=42)\n",
    "test_df_1 = test_df_1.sample(frac=1, random_state=42)\n",
    "test_df_2 = test_df_2.sample(frac=1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b43e3ced-a60e-4cf5-8f4a-1e6ca4f7e3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(row):\n",
    "  sequence = str(row[\"paragraph1\"]) + \"[LP2]\" + str(row[\"paragraph2\"])\n",
    "  return sequence\n",
    "\n",
    "# train_df[\"input\"] = train_df.apply(create_sequences, axis=1)\n",
    "# val_df[\"input\"] = val_df.apply(create_sequences, axis=1)\n",
    "\n",
    "def create_multilabel(row):\n",
    "  label_dataset = max(min(1, row[\"label_dataset\"]), 0)\n",
    "  multilabel = np.array([int(row[\"label_author\"]), int(label_dataset)])\n",
    "  return multilabel\n",
    "\n",
    "def create_singlelabel(row):\n",
    "  label = np.array([int(row[\"label_author\"])])\n",
    "  return label\n",
    "\n",
    "if author_label_only:\n",
    "  test_df_0[\"label\"] = test_df_0.apply(create_singlelabel, axis=1)\n",
    "  test_df_1[\"label\"] = test_df_1.apply(create_singlelabel, axis=1)\n",
    "  test_df_2[\"label\"] = test_df_2.apply(create_singlelabel, axis=1)\n",
    "else:\n",
    "  test_df_0[\"label\"] = test_df_0.apply(create_multilabel, axis=1)\n",
    "  test_df_1[\"label\"] = test_df_1.apply(create_multilabel, axis=1)\n",
    "  test_df_2[\"label\"] = test_df_2.apply(create_multilabel, axis=1)\n",
    "  # weight author label heavier than topic change label\n",
    "\n",
    "y_test_0 = test_df_0[\"label\"].values\n",
    "y_test_0 = np.stack(y_test_0)\n",
    "y_test_1 = test_df_1[\"label\"].values\n",
    "y_test_1 = np.stack(y_test_1)\n",
    "y_test_2 = test_df_2[\"label\"].values\n",
    "y_test_2 = np.stack(y_test_2)\n",
    "\n",
    "x_test_par1_0 = test_df_0[\"paragraph1\"].values\n",
    "x_test_par2_0 = test_df_0[\"paragraph2\"].values\n",
    "x_test_par1_1 = test_df_1[\"paragraph1\"].values\n",
    "x_test_par2_1 = test_df_1[\"paragraph2\"].values\n",
    "x_test_par1_2 = test_df_2[\"paragraph1\"].values\n",
    "x_test_par2_2 = test_df_2[\"paragraph2\"].values\n",
    "\n",
    "ds = DatasetDict({\n",
    "    'test_0': Dataset.from_dict({'paragraph1': x_test_par1_0, 'paragraph2': x_test_par2_0, 'labels': y_test_0}),\n",
    "    'test_1': Dataset.from_dict({'paragraph1': x_test_par1_1, 'paragraph2': x_test_par2_1, 'labels': y_test_1}),\n",
    "    'test_2': Dataset.from_dict({'paragraph1': x_test_par1_2, 'paragraph2': x_test_par2_2, 'labels': y_test_2}),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1a6db41-79a6-43a9-a924-152e79d7b9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e163a4261545b5a8773544ebbcee11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('filipealmeida/Mistral-7B-v0.1-sharded')\n",
    "\n",
    "model = AutoModel.from_pretrained('filipealmeida/Mistral-7B-v0.1-sharded', load_in_4bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57293852-4e00-457b-97da-74bb1f1755e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_token_pool(last_hidden_states, attention_mask):\n",
    "  left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "  if left_padding:\n",
    "    return last_hidden_states[:, -1]\n",
    "  else:\n",
    "    sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "    batch_size = last_hidden_states.shape[0]\n",
    "    return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    max_length = 4096\n",
    "    embeddings1_list = []\n",
    "    embeddings2_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for sample in batch:\n",
    "        paragraph1 = sample['paragraph1']\n",
    "        paragraph2 = sample['paragraph2']\n",
    "        labels = sample['labels']\n",
    "        labels_list.append(labels)\n",
    "\n",
    "        inputs1 = tokenizer(paragraph1, max_length=max_length, truncation=True, return_tensors='pt')\n",
    "        inputs2 = tokenizer(paragraph2, max_length=max_length, truncation=True, return_tensors='pt')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs1 = model(**inputs1)\n",
    "            embeddings1 = last_token_pool(outputs1.last_hidden_state, inputs1['attention_mask'])\n",
    "\n",
    "            outputs2 = model(**inputs2)\n",
    "            embeddings2 = last_token_pool(outputs2.last_hidden_state, inputs2['attention_mask'])\n",
    "\n",
    "        embeddings1_list.append(embeddings1.float())\n",
    "        embeddings2_list.append(embeddings2.float())\n",
    "\n",
    "    embeddings1_batch = torch.stack(embeddings1_list, dim=0)\n",
    "    embeddings2_batch = torch.stack(embeddings2_list, dim=0)\n",
    "    labels_batch = torch.tensor(labels_list)\n",
    "\n",
    "    return embeddings1_batch, embeddings2_batch, labels_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbef5a45-abcf-4e7f-8834-ae222357d91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (fc1): Linear(in_features=8192, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model architecture for the classifier\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, number_labels=1):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size * 2, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, number_labels)  # Assuming binary classification\n",
    "\n",
    "    def forward(self, emb1, emb2):\n",
    "        # Concatenate embeddings along the last dimension\n",
    "        x = torch.cat((emb1, emb2), dim=2)  # Shape: [batch_size, input_size * 2]\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# define params\n",
    "if author_label_only:\n",
    "  number_labels = 1  # or 2 for binary classification with two labels\n",
    "else:\n",
    "  number_labels = 2\n",
    "batch_size = 16\n",
    "input_size = 4096 # needs to be set as well above\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model_save_path = 'emb_org_b/model.pth'\n",
    "# Instantiate the model\n",
    "classifier = Classifier(input_size, number_labels)\n",
    "\n",
    "# Load the saved model weights\n",
    "classifier.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "classifier.eval()\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "classifier.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b811b13d-516a-4bce-bd7f-82cea0194929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_loader):\n",
    "    # List to store predictions and true labels\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    losses = []\n",
    "    \n",
    "    # Disable gradient computation for evaluation\n",
    "    with torch.no_grad():\n",
    "        for batch_embeddings1, batch_embeddings2, target in test_loader:\n",
    "            batch_embeddings1 = batch_embeddings1.to(device).float()\n",
    "            batch_embeddings2 = batch_embeddings2.to(device).float()\n",
    "            target = target.to(device).float()\n",
    "    \n",
    "            # Forward pass\n",
    "            output = classifier(batch_embeddings1, batch_embeddings2)\n",
    "    \n",
    "            # Calculate the loss\n",
    "            if number_labels == 2:\n",
    "                loss = loss_function(output.squeeze(), target.float())\n",
    "            else:\n",
    "                loss = loss_function(output.squeeze(), target.squeeze().float())\n",
    "                losses.append(val_loss.item())\n",
    "            \n",
    "            # Apply sigmoid to get probabilities, then round to get binary predictions\n",
    "            # Calculate predictions\n",
    "            predictions = torch.sigmoid(output).round().squeeze()\n",
    "            all_predictions.extend(predictions.cpu().tolist())\n",
    "            all_labels.extend(target.cpu().tolist())\n",
    "            \n",
    "            # convert predictions and target to right format\n",
    "            predictions = torch.sigmoid(output).round().squeeze().cpu().tolist()\n",
    "            target = target.cpu().tolist()\n",
    "            \n",
    "            # calculate scores\n",
    "            train_f1_macro = f1_score(target, predictions, average=\"macro\")\n",
    "            \n",
    "            if number_labels == 2:\n",
    "                f1_macro_author = f1_score([[row[0]] for row in target], [[row[0]] for row in predictions])\n",
    "                print({\"loss\": loss, \"train_macro_f1\": train_f1_macro, \"train_macro_f1_author\": f1_macro_author})\n",
    "            else:\n",
    "                print({\"loss\": loss, \"train_macro_f1\": train_f1_macro})\n",
    "    \n",
    "    print(\"Overall Results\")\n",
    "    \n",
    "    # Calculate validation metrics\n",
    "    val_f1_macro = f1_score(all_labels, all_predictions, average=\"macro\")\n",
    "    val_f1_micro = f1_score(all_labels, all_predictions, average=\"micro\")\n",
    "    epoch = 0\n",
    "    scores = {'epoch': epoch+1, 'loss': loss.item(), 'val_f1_macro': val_f1_macro, 'val_f1_micro': val_f1_micro}\n",
    "    if number_labels == 2:\n",
    "        f1_macro_author = f1_score([[row[0]] for row in all_labels], [[row[0]] for row in all_predictions])\n",
    "        scores['val_f1_author'] = f1_macro_author\n",
    "        # Log validation metrics to wandb\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93aeb91c-a9cc-488a-b9a6-b01d698b78cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.7068, device='cuda:0'), 'train_macro_f1': 0.4666666666666667, 'train_macro_f1_author': 0.9333333333333333}\n",
      "{'loss': tensor(0.7905, device='cuda:0'), 'train_macro_f1': 0.4666666666666667, 'train_macro_f1_author': 0.9333333333333333}\n",
      "{'loss': tensor(0.5944, device='cuda:0'), 'train_macro_f1': 0.4666666666666667, 'train_macro_f1_author': 0.9333333333333333}\n",
      "{'loss': tensor(0.4881, device='cuda:0'), 'train_macro_f1': 0.4482758620689655, 'train_macro_f1_author': 0.896551724137931}\n",
      "{'loss': tensor(0.6858, device='cuda:0'), 'train_macro_f1': 0.4666666666666667, 'train_macro_f1_author': 0.9333333333333333}\n",
      "{'loss': tensor(0.8938, device='cuda:0'), 'train_macro_f1': 0.44, 'train_macro_f1_author': 0.88}\n",
      "{'loss': tensor(1.0109, device='cuda:0'), 'train_macro_f1': 0.38095238095238093, 'train_macro_f1_author': 0.7619047619047619}\n",
      "{'loss': tensor(0.5188, device='cuda:0'), 'train_macro_f1': 0.4827586206896552, 'train_macro_f1_author': 0.9655172413793104}\n",
      "{'loss': tensor(0.6800, device='cuda:0'), 'train_macro_f1': 0.4642857142857143, 'train_macro_f1_author': 0.9285714285714286}\n",
      "{'loss': tensor(0.6817, device='cuda:0'), 'train_macro_f1': 0.46153846153846156, 'train_macro_f1_author': 0.9230769230769231}\n",
      "{'loss': tensor(0.7218, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.4417, device='cuda:0'), 'train_macro_f1': 0.4827586206896552, 'train_macro_f1_author': 0.9655172413793104}\n",
      "{'loss': tensor(0.6466, device='cuda:0'), 'train_macro_f1': 0.4827586206896552, 'train_macro_f1_author': 0.9655172413793104}\n",
      "{'loss': tensor(0.3665, device='cuda:0'), 'train_macro_f1': 0.4827586206896552, 'train_macro_f1_author': 0.9655172413793104}\n",
      "{'loss': tensor(0.5007, device='cuda:0'), 'train_macro_f1': 0.4838709677419355, 'train_macro_f1_author': 0.967741935483871}\n",
      "{'loss': tensor(0.6863, device='cuda:0'), 'train_macro_f1': 0.4642857142857143, 'train_macro_f1_author': 0.9285714285714286}\n",
      "{'loss': tensor(0.7068, device='cuda:0'), 'train_macro_f1': 0.4827586206896552, 'train_macro_f1_author': 0.9655172413793104}\n",
      "{'loss': tensor(0.7081, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.4045, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.5863, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.6678, device='cuda:0'), 'train_macro_f1': 0.4444444444444444, 'train_macro_f1_author': 0.8888888888888888}\n",
      "{'loss': tensor(0.6744, device='cuda:0'), 'train_macro_f1': 0.4838709677419355, 'train_macro_f1_author': 0.967741935483871}\n",
      "{'loss': tensor(0.5834, device='cuda:0'), 'train_macro_f1': 0.4827586206896552, 'train_macro_f1_author': 0.9655172413793104}\n",
      "{'loss': tensor(0.6941, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.5200, device='cuda:0'), 'train_macro_f1': 0.4827586206896552, 'train_macro_f1_author': 0.9655172413793104}\n",
      "{'loss': tensor(0.6743, device='cuda:0'), 'train_macro_f1': 0.48148148148148145, 'train_macro_f1_author': 0.9629629629629629}\n",
      "{'loss': tensor(0.6142, device='cuda:0'), 'train_macro_f1': 0.4838709677419355, 'train_macro_f1_author': 0.967741935483871}\n",
      "{'loss': tensor(0.7053, device='cuda:0'), 'train_macro_f1': 0.4827586206896552, 'train_macro_f1_author': 0.9655172413793104}\n",
      "{'loss': tensor(0.4581, device='cuda:0'), 'train_macro_f1': 0.4838709677419355, 'train_macro_f1_author': 0.967741935483871}\n",
      "{'loss': tensor(0.4281, device='cuda:0'), 'train_macro_f1': 0.4838709677419355, 'train_macro_f1_author': 0.967741935483871}\n",
      "{'loss': tensor(0.7552, device='cuda:0'), 'train_macro_f1': 0.4482758620689655, 'train_macro_f1_author': 0.896551724137931}\n",
      "{'loss': tensor(0.7076, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.4234, device='cuda:0'), 'train_macro_f1': 0.4642857142857143, 'train_macro_f1_author': 0.9285714285714286}\n",
      "{'loss': tensor(0.6784, device='cuda:0'), 'train_macro_f1': 0.48, 'train_macro_f1_author': 0.96}\n",
      "{'loss': tensor(0.7769, device='cuda:0'), 'train_macro_f1': 0.4782608695652174, 'train_macro_f1_author': 0.9565217391304348}\n",
      "{'loss': tensor(0.5712, device='cuda:0'), 'train_macro_f1': 0.4666666666666667, 'train_macro_f1_author': 0.9333333333333333}\n",
      "{'loss': tensor(0.6711, device='cuda:0'), 'train_macro_f1': 0.4482758620689655, 'train_macro_f1_author': 0.896551724137931}\n",
      "{'loss': tensor(0.5853, device='cuda:0'), 'train_macro_f1': 0.4642857142857143, 'train_macro_f1_author': 0.9285714285714286}\n",
      "{'loss': tensor(0.5611, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.6802, device='cuda:0'), 'train_macro_f1': 0.4827586206896552, 'train_macro_f1_author': 0.9655172413793104}\n",
      "{'loss': tensor(0.2920, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.8828, device='cuda:0'), 'train_macro_f1': 0.4482758620689655, 'train_macro_f1_author': 0.896551724137931}\n",
      "{'loss': tensor(0.5191, device='cuda:0'), 'train_macro_f1': 0.4827586206896552, 'train_macro_f1_author': 0.9655172413793104}\n",
      "{'loss': tensor(0.5576, device='cuda:0'), 'train_macro_f1': 0.4827586206896552, 'train_macro_f1_author': 0.9655172413793104}\n",
      "{'loss': tensor(0.5797, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.6419, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.5038, device='cuda:0'), 'train_macro_f1': 0.4838709677419355, 'train_macro_f1_author': 0.967741935483871}\n",
      "{'loss': tensor(0.7242, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.6420, device='cuda:0'), 'train_macro_f1': 0.4666666666666667, 'train_macro_f1_author': 0.9333333333333333}\n",
      "{'loss': tensor(0.4234, device='cuda:0'), 'train_macro_f1': 0.4827586206896552, 'train_macro_f1_author': 0.9655172413793104}\n",
      "{'loss': tensor(0.3808, device='cuda:0'), 'train_macro_f1': 0.4482758620689655, 'train_macro_f1_author': 0.896551724137931}\n",
      "{'loss': tensor(0.4118, device='cuda:0'), 'train_macro_f1': 0.4838709677419355, 'train_macro_f1_author': 0.967741935483871}\n",
      "{'loss': tensor(0.4658, device='cuda:0'), 'train_macro_f1': 0.4838709677419355, 'train_macro_f1_author': 0.967741935483871}\n",
      "{'loss': tensor(0.3928, device='cuda:0'), 'train_macro_f1': 0.4838709677419355, 'train_macro_f1_author': 0.967741935483871}\n",
      "{'loss': tensor(0.4567, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.2752, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.6211, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.5500, device='cuda:0'), 'train_macro_f1': 0.4444444444444444, 'train_macro_f1_author': 0.8888888888888888}\n",
      "{'loss': tensor(0.6025, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.3901, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.5391, device='cuda:0'), 'train_macro_f1': 0.4482758620689655, 'train_macro_f1_author': 0.896551724137931}\n",
      "{'loss': tensor(0.6073, device='cuda:0'), 'train_macro_f1': 0.4827586206896552, 'train_macro_f1_author': 0.9655172413793104}\n",
      "{'loss': tensor(0.6613, device='cuda:0'), 'train_macro_f1': 0.38461538461538464, 'train_macro_f1_author': 0.7692307692307693}\n",
      "{'loss': tensor(0.7601, device='cuda:0'), 'train_macro_f1': 0.4642857142857143, 'train_macro_f1_author': 0.9285714285714286}\n",
      "{'loss': tensor(0.4714, device='cuda:0'), 'train_macro_f1': 0.4838709677419355, 'train_macro_f1_author': 0.967741935483871}\n",
      "{'loss': tensor(0.3764, device='cuda:0'), 'train_macro_f1': 0.4838709677419355, 'train_macro_f1_author': 0.967741935483871}\n",
      "{'loss': tensor(0.4790, device='cuda:0'), 'train_macro_f1': 0.4838709677419355, 'train_macro_f1_author': 0.967741935483871}\n",
      "{'loss': tensor(0.3343, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.6459, device='cuda:0'), 'train_macro_f1': 0.4827586206896552, 'train_macro_f1_author': 0.9655172413793104}\n",
      "{'loss': tensor(0.4690, device='cuda:0'), 'train_macro_f1': 0.48148148148148145, 'train_macro_f1_author': 0.9629629629629629}\n",
      "{'loss': tensor(0.4411, device='cuda:0'), 'train_macro_f1': 0.4827586206896552, 'train_macro_f1_author': 0.9655172413793104}\n",
      "{'loss': tensor(0.4352, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.4524, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.4229, device='cuda:0'), 'train_macro_f1': 0.4838709677419355, 'train_macro_f1_author': 0.967741935483871}\n",
      "{'loss': tensor(0.8264, device='cuda:0'), 'train_macro_f1': 0.4230769230769231, 'train_macro_f1_author': 0.8461538461538461}\n",
      "{'loss': tensor(0.4598, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.5305, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.6104, device='cuda:0'), 'train_macro_f1': 0.4642857142857143, 'train_macro_f1_author': 0.9285714285714286}\n",
      "{'loss': tensor(0.5338, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.6184, device='cuda:0'), 'train_macro_f1': 0.4666666666666667, 'train_macro_f1_author': 0.9333333333333333}\n",
      "{'loss': tensor(0.6834, device='cuda:0'), 'train_macro_f1': 0.48, 'train_macro_f1_author': 0.96}\n",
      "{'loss': tensor(0.5916, device='cuda:0'), 'train_macro_f1': 0.4642857142857143, 'train_macro_f1_author': 0.9285714285714286}\n",
      "{'loss': tensor(0.7099, device='cuda:0'), 'train_macro_f1': 0.4642857142857143, 'train_macro_f1_author': 0.9285714285714286}\n",
      "{'loss': tensor(0.5362, device='cuda:0'), 'train_macro_f1': 0.4838709677419355, 'train_macro_f1_author': 0.967741935483871}\n",
      "{'loss': tensor(0.4965, device='cuda:0'), 'train_macro_f1': 0.4666666666666667, 'train_macro_f1_author': 0.9333333333333333}\n",
      "{'loss': tensor(0.4728, device='cuda:0'), 'train_macro_f1': 0.4838709677419355, 'train_macro_f1_author': 0.967741935483871}\n",
      "{'loss': tensor(0.5297, device='cuda:0'), 'train_macro_f1': 0.4838709677419355, 'train_macro_f1_author': 0.967741935483871}\n",
      "{'loss': tensor(0.5392, device='cuda:0'), 'train_macro_f1': 0.4827586206896552, 'train_macro_f1_author': 0.9655172413793104}\n",
      "{'loss': tensor(0.6019, device='cuda:0'), 'train_macro_f1': 0.4666666666666667, 'train_macro_f1_author': 0.9333333333333333}\n",
      "{'loss': tensor(0.7031, device='cuda:0'), 'train_macro_f1': 0.4666666666666667, 'train_macro_f1_author': 0.9333333333333333}\n",
      "{'loss': tensor(0.5744, device='cuda:0'), 'train_macro_f1': 0.46153846153846156, 'train_macro_f1_author': 0.9230769230769231}\n",
      "{'loss': tensor(0.4335, device='cuda:0'), 'train_macro_f1': 0.4838709677419355, 'train_macro_f1_author': 0.967741935483871}\n",
      "{'loss': tensor(0.5640, device='cuda:0'), 'train_macro_f1': 0.4642857142857143, 'train_macro_f1_author': 0.9285714285714286}\n",
      "{'loss': tensor(0.1866, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.4652, device='cuda:0'), 'train_macro_f1': 0.4666666666666667, 'train_macro_f1_author': 0.9333333333333333}\n",
      "{'loss': tensor(0.4735, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.5045, device='cuda:0'), 'train_macro_f1': 0.4666666666666667, 'train_macro_f1_author': 0.9333333333333333}\n",
      "{'loss': tensor(0.3867, device='cuda:0'), 'train_macro_f1': 0.4838709677419355, 'train_macro_f1_author': 0.967741935483871}\n",
      "{'loss': tensor(0.4782, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.5017, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.6912, device='cuda:0'), 'train_macro_f1': 0.48148148148148145, 'train_macro_f1_author': 0.9629629629629629}\n",
      "{'loss': tensor(0.3034, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.6859, device='cuda:0'), 'train_macro_f1': 0.4666666666666667, 'train_macro_f1_author': 0.9333333333333333}\n",
      "{'loss': tensor(0.4199, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.5884, device='cuda:0'), 'train_macro_f1': 0.48148148148148145, 'train_macro_f1_author': 0.9629629629629629}\n",
      "{'loss': tensor(0.9630, device='cuda:0'), 'train_macro_f1': 0.4444444444444444, 'train_macro_f1_author': 0.8888888888888888}\n",
      "{'loss': tensor(0.4705, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.5138, device='cuda:0'), 'train_macro_f1': 0.4666666666666667, 'train_macro_f1_author': 0.9333333333333333}\n",
      "{'loss': tensor(0.8933, device='cuda:0'), 'train_macro_f1': 0.4482758620689655, 'train_macro_f1_author': 0.896551724137931}\n",
      "{'loss': tensor(0.5133, device='cuda:0'), 'train_macro_f1': 0.48148148148148145, 'train_macro_f1_author': 0.9629629629629629}\n",
      "{'loss': tensor(0.6884, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.5177, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.4991, device='cuda:0'), 'train_macro_f1': 0.4666666666666667, 'train_macro_f1_author': 0.9333333333333333}\n",
      "{'loss': tensor(0.4211, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.5443, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.7197, device='cuda:0'), 'train_macro_f1': 0.4838709677419355, 'train_macro_f1_author': 0.967741935483871}\n",
      "{'loss': tensor(0.3902, device='cuda:0'), 'train_macro_f1': 0.4666666666666667, 'train_macro_f1_author': 0.9333333333333333}\n",
      "{'loss': tensor(0.8488, device='cuda:0'), 'train_macro_f1': 0.4230769230769231, 'train_macro_f1_author': 0.8461538461538461}\n",
      "{'loss': tensor(0.5821, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.7150, device='cuda:0'), 'train_macro_f1': 0.4827586206896552, 'train_macro_f1_author': 0.9655172413793104}\n",
      "{'loss': tensor(0.2047, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.4828, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.6179, device='cuda:0'), 'train_macro_f1': 0.46153846153846156, 'train_macro_f1_author': 0.9230769230769231}\n",
      "{'loss': tensor(0.7251, device='cuda:0'), 'train_macro_f1': 0.4838709677419355, 'train_macro_f1_author': 0.967741935483871}\n",
      "{'loss': tensor(0.3326, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.5352, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.5903, device='cuda:0'), 'train_macro_f1': 0.4666666666666667, 'train_macro_f1_author': 0.9333333333333333}\n",
      "{'loss': tensor(0.4321, device='cuda:0'), 'train_macro_f1': 0.4838709677419355, 'train_macro_f1_author': 0.967741935483871}\n",
      "{'loss': tensor(0.7091, device='cuda:0'), 'train_macro_f1': 0.4444444444444444, 'train_macro_f1_author': 0.8888888888888888}\n",
      "{'loss': tensor(0.6032, device='cuda:0'), 'train_macro_f1': 0.4666666666666667, 'train_macro_f1_author': 0.9333333333333333}\n",
      "{'loss': tensor(0.4112, device='cuda:0'), 'train_macro_f1': 0.4827586206896552, 'train_macro_f1_author': 0.9655172413793104}\n",
      "{'loss': tensor(0.6366, device='cuda:0'), 'train_macro_f1': 0.4642857142857143, 'train_macro_f1_author': 0.9285714285714286}\n",
      "{'loss': tensor(0.5641, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.7605, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.5622, device='cuda:0'), 'train_macro_f1': 0.48148148148148145, 'train_macro_f1_author': 0.9629629629629629}\n",
      "{'loss': tensor(0.6747, device='cuda:0'), 'train_macro_f1': 0.4827586206896552, 'train_macro_f1_author': 0.9655172413793104}\n",
      "{'loss': tensor(0.4181, device='cuda:0'), 'train_macro_f1': 0.4827586206896552, 'train_macro_f1_author': 0.9655172413793104}\n",
      "{'loss': tensor(0.6460, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.6107, device='cuda:0'), 'train_macro_f1': 0.4827586206896552, 'train_macro_f1_author': 0.9655172413793104}\n",
      "{'loss': tensor(0.3551, device='cuda:0'), 'train_macro_f1': 0.5, 'train_macro_f1_author': 1.0}\n",
      "Overall Results\n",
      "{'epoch': 1, 'loss': 0.35510310530662537, 'val_f1_macro': 0.47956204379562045, 'val_f1_micro': 0.7635095874491574, 'val_f1_author': 0.9591240875912409}\n",
      "{'loss': tensor(0.2656, device='cuda:0'), 'train_macro_f1': 0.8588709677419355, 'train_macro_f1_author': 0.75}\n",
      "{'loss': tensor(0.2058, device='cuda:0'), 'train_macro_f1': 0.9285714285714286, 'train_macro_f1_author': 0.8571428571428571}\n",
      "{'loss': tensor(0.2198, device='cuda:0'), 'train_macro_f1': 0.9090909090909092, 'train_macro_f1_author': 0.8181818181818182}\n",
      "{'loss': tensor(0.1424, device='cuda:0'), 'train_macro_f1': 0.9761904761904762, 'train_macro_f1_author': 0.9523809523809523}\n",
      "{'loss': tensor(0.2477, device='cuda:0'), 'train_macro_f1': 0.8809523809523809, 'train_macro_f1_author': 0.7619047619047619}\n",
      "{'loss': tensor(0.2426, device='cuda:0'), 'train_macro_f1': 0.9, 'train_macro_f1_author': 0.8}\n",
      "{'loss': tensor(0.3816, device='cuda:0'), 'train_macro_f1': 0.9186535764375876, 'train_macro_f1_author': 0.8695652173913043}\n",
      "{'loss': tensor(0.3275, device='cuda:0'), 'train_macro_f1': 0.8529411764705883, 'train_macro_f1_author': 0.7058823529411765}\n",
      "{'loss': tensor(0.2193, device='cuda:0'), 'train_macro_f1': 0.8929618768328447, 'train_macro_f1_author': 0.8181818181818182}\n",
      "{'loss': tensor(0.1214, device='cuda:0'), 'train_macro_f1': 0.95, 'train_macro_f1_author': 0.9}\n",
      "{'loss': tensor(0.2024, device='cuda:0'), 'train_macro_f1': 0.868421052631579, 'train_macro_f1_author': 0.7368421052631579}\n",
      "{'loss': tensor(0.2373, device='cuda:0'), 'train_macro_f1': 0.9111111111111111, 'train_macro_f1_author': 0.8888888888888888}\n",
      "{'loss': tensor(0.2836, device='cuda:0'), 'train_macro_f1': 0.8809523809523809, 'train_macro_f1_author': 0.7619047619047619}\n",
      "{'loss': tensor(0.2576, device='cuda:0'), 'train_macro_f1': 0.9117647058823529, 'train_macro_f1_author': 0.8235294117647058}\n",
      "{'loss': tensor(0.2741, device='cuda:0'), 'train_macro_f1': 0.9117647058823529, 'train_macro_f1_author': 0.8235294117647058}\n",
      "{'loss': tensor(0.2069, device='cuda:0'), 'train_macro_f1': 0.9210526315789473, 'train_macro_f1_author': 0.8421052631578947}\n",
      "{'loss': tensor(0.2371, device='cuda:0'), 'train_macro_f1': 0.8888888888888888, 'train_macro_f1_author': 0.7777777777777778}\n",
      "{'loss': tensor(0.2170, device='cuda:0'), 'train_macro_f1': 0.9210526315789473, 'train_macro_f1_author': 0.8421052631578947}\n",
      "{'loss': tensor(0.3213, device='cuda:0'), 'train_macro_f1': 0.8838709677419355, 'train_macro_f1_author': 0.8}\n",
      "{'loss': tensor(0.2942, device='cuda:0'), 'train_macro_f1': 0.8238095238095238, 'train_macro_f1_author': 0.7142857142857143}\n",
      "{'loss': tensor(0.2052, device='cuda:0'), 'train_macro_f1': 0.9444444444444444, 'train_macro_f1_author': 0.8888888888888888}\n",
      "{'loss': tensor(0.2151, device='cuda:0'), 'train_macro_f1': 0.8838709677419355, 'train_macro_f1_author': 0.8}\n",
      "{'loss': tensor(0.2769, device='cuda:0'), 'train_macro_f1': 0.8888888888888888, 'train_macro_f1_author': 0.7777777777777778}\n",
      "{'loss': tensor(0.1690, device='cuda:0'), 'train_macro_f1': 0.9166666666666667, 'train_macro_f1_author': 0.8333333333333334}\n",
      "{'loss': tensor(0.1827, device='cuda:0'), 'train_macro_f1': 0.9666666666666667, 'train_macro_f1_author': 0.9333333333333333}\n",
      "{'loss': tensor(0.2933, device='cuda:0'), 'train_macro_f1': 0.8913043478260869, 'train_macro_f1_author': 0.782608695652174}\n",
      "{'loss': tensor(0.2696, device='cuda:0'), 'train_macro_f1': 0.9186535764375876, 'train_macro_f1_author': 0.8695652173913043}\n",
      "{'loss': tensor(0.2201, device='cuda:0'), 'train_macro_f1': 0.9545454545454546, 'train_macro_f1_author': 0.9090909090909091}\n",
      "{'loss': tensor(0.2661, device='cuda:0'), 'train_macro_f1': 0.9210526315789473, 'train_macro_f1_author': 0.8421052631578947}\n",
      "{'loss': tensor(0.2151, device='cuda:0'), 'train_macro_f1': 0.95, 'train_macro_f1_author': 0.9}\n",
      "{'loss': tensor(0.1724, device='cuda:0'), 'train_macro_f1': 0.9347826086956521, 'train_macro_f1_author': 0.8695652173913043}\n",
      "{'loss': tensor(0.2863, device='cuda:0'), 'train_macro_f1': 0.8809523809523809, 'train_macro_f1_author': 0.7619047619047619}\n",
      "{'loss': tensor(0.3421, device='cuda:0'), 'train_macro_f1': 0.868421052631579, 'train_macro_f1_author': 0.7368421052631579}\n",
      "{'loss': tensor(0.1393, device='cuda:0'), 'train_macro_f1': 0.9583333333333333, 'train_macro_f1_author': 0.9166666666666666}\n",
      "{'loss': tensor(0.1853, device='cuda:0'), 'train_macro_f1': 0.9210526315789473, 'train_macro_f1_author': 0.8421052631578947}\n",
      "{'loss': tensor(0.2018, device='cuda:0'), 'train_macro_f1': 0.9444444444444444, 'train_macro_f1_author': 0.8888888888888888}\n",
      "{'loss': tensor(0.2650, device='cuda:0'), 'train_macro_f1': 0.9285714285714286, 'train_macro_f1_author': 0.8571428571428571}\n",
      "{'loss': tensor(0.0992, device='cuda:0'), 'train_macro_f1': 0.9666666666666667, 'train_macro_f1_author': 0.9333333333333333}\n",
      "{'loss': tensor(0.2121, device='cuda:0'), 'train_macro_f1': 0.9238709677419354, 'train_macro_f1_author': 0.88}\n",
      "{'loss': tensor(0.2346, device='cuda:0'), 'train_macro_f1': 0.9444444444444444, 'train_macro_f1_author': 0.8888888888888888}\n",
      "{'loss': tensor(0.2558, device='cuda:0'), 'train_macro_f1': 0.9, 'train_macro_f1_author': 0.8}\n",
      "{'loss': tensor(0.3184, device='cuda:0'), 'train_macro_f1': 0.8172043010752688, 'train_macro_f1_author': 0.6666666666666666}\n",
      "{'loss': tensor(0.2285, device='cuda:0'), 'train_macro_f1': 0.9444444444444444, 'train_macro_f1_author': 0.8888888888888888}\n",
      "{'loss': tensor(0.1543, device='cuda:0'), 'train_macro_f1': 1.0, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.2692, device='cuda:0'), 'train_macro_f1': 0.875, 'train_macro_f1_author': 0.75}\n",
      "{'loss': tensor(0.1832, device='cuda:0'), 'train_macro_f1': 0.9444444444444444, 'train_macro_f1_author': 0.8888888888888888}\n",
      "{'loss': tensor(0.2249, device='cuda:0'), 'train_macro_f1': 0.9736842105263157, 'train_macro_f1_author': 0.9473684210526315}\n",
      "{'loss': tensor(0.2666, device='cuda:0'), 'train_macro_f1': 0.8333333333333333, 'train_macro_f1_author': 0.6666666666666666}\n",
      "{'loss': tensor(0.2836, device='cuda:0'), 'train_macro_f1': 0.8529411764705883, 'train_macro_f1_author': 0.7058823529411765}\n",
      "{'loss': tensor(0.3034, device='cuda:0'), 'train_macro_f1': 0.8125, 'train_macro_f1_author': 0.625}\n",
      "{'loss': tensor(0.3023, device='cuda:0'), 'train_macro_f1': 0.8522920203735145, 'train_macro_f1_author': 0.7368421052631579}\n",
      "{'loss': tensor(0.2272, device='cuda:0'), 'train_macro_f1': 0.9285714285714286, 'train_macro_f1_author': 0.8571428571428571}\n",
      "{'loss': tensor(0.1897, device='cuda:0'), 'train_macro_f1': 0.9736842105263157, 'train_macro_f1_author': 0.9473684210526315}\n",
      "{'loss': tensor(0.2689, device='cuda:0'), 'train_macro_f1': 0.8809523809523809, 'train_macro_f1_author': 0.7619047619047619}\n",
      "{'loss': tensor(0.2606, device='cuda:0'), 'train_macro_f1': 0.8913043478260869, 'train_macro_f1_author': 0.782608695652174}\n",
      "{'loss': tensor(0.2396, device='cuda:0'), 'train_macro_f1': 0.9, 'train_macro_f1_author': 0.8}\n",
      "{'loss': tensor(0.2087, device='cuda:0'), 'train_macro_f1': 0.9347826086956521, 'train_macro_f1_author': 0.8695652173913043}\n",
      "{'loss': tensor(0.2826, device='cuda:0'), 'train_macro_f1': 0.9, 'train_macro_f1_author': 0.8}\n",
      "{'loss': tensor(0.3167, device='cuda:0'), 'train_macro_f1': 0.8333333333333333, 'train_macro_f1_author': 0.6666666666666666}\n",
      "{'loss': tensor(0.2223, device='cuda:0'), 'train_macro_f1': 0.9444444444444444, 'train_macro_f1_author': 0.8888888888888888}\n",
      "{'loss': tensor(0.3000, device='cuda:0'), 'train_macro_f1': 0.9066666666666667, 'train_macro_f1_author': 0.88}\n",
      "{'loss': tensor(0.2342, device='cuda:0'), 'train_macro_f1': 0.9285714285714286, 'train_macro_f1_author': 0.8571428571428571}\n",
      "{'loss': tensor(0.2054, device='cuda:0'), 'train_macro_f1': 0.9736842105263157, 'train_macro_f1_author': 0.9473684210526315}\n",
      "{'loss': tensor(0.3017, device='cuda:0'), 'train_macro_f1': 0.8125, 'train_macro_f1_author': 0.625}\n",
      "{'loss': tensor(0.2859, device='cuda:0'), 'train_macro_f1': 0.875, 'train_macro_f1_author': 0.75}\n",
      "{'loss': tensor(0.2897, device='cuda:0'), 'train_macro_f1': 0.8929618768328447, 'train_macro_f1_author': 0.8181818181818182}\n",
      "{'loss': tensor(0.2958, device='cuda:0'), 'train_macro_f1': 0.9166666666666667, 'train_macro_f1_author': 0.8333333333333334}\n",
      "{'loss': tensor(0.2124, device='cuda:0'), 'train_macro_f1': 0.9, 'train_macro_f1_author': 0.8}\n",
      "{'loss': tensor(0.2698, device='cuda:0'), 'train_macro_f1': 0.9782608695652174, 'train_macro_f1_author': 0.9565217391304348}\n",
      "{'loss': tensor(0.1946, device='cuda:0'), 'train_macro_f1': 0.9422043010752688, 'train_macro_f1_author': 0.9166666666666666}\n",
      "{'loss': tensor(0.2091, device='cuda:0'), 'train_macro_f1': 0.8888888888888888, 'train_macro_f1_author': 0.7777777777777778}\n",
      "{'loss': tensor(0.2260, device='cuda:0'), 'train_macro_f1': 0.9, 'train_macro_f1_author': 0.8}\n",
      "{'loss': tensor(0.2106, device='cuda:0'), 'train_macro_f1': 0.9210526315789473, 'train_macro_f1_author': 0.8421052631578947}\n",
      "{'loss': tensor(0.1029, device='cuda:0'), 'train_macro_f1': 1.0, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.0968, device='cuda:0'), 'train_macro_f1': 0.9761904761904762, 'train_macro_f1_author': 0.9523809523809523}\n",
      "{'loss': tensor(0.2488, device='cuda:0'), 'train_macro_f1': 0.9117647058823529, 'train_macro_f1_author': 0.8235294117647058}\n",
      "{'loss': tensor(0.2613, device='cuda:0'), 'train_macro_f1': 0.8333333333333333, 'train_macro_f1_author': 0.6666666666666666}\n",
      "{'loss': tensor(0.2234, device='cuda:0'), 'train_macro_f1': 0.95, 'train_macro_f1_author': 0.9}\n",
      "{'loss': tensor(0.2064, device='cuda:0'), 'train_macro_f1': 0.9782608695652174, 'train_macro_f1_author': 0.9565217391304348}\n",
      "{'loss': tensor(0.1920, device='cuda:0'), 'train_macro_f1': 0.95, 'train_macro_f1_author': 0.9}\n",
      "{'loss': tensor(0.1735, device='cuda:0'), 'train_macro_f1': 0.9615384615384616, 'train_macro_f1_author': 0.9230769230769231}\n",
      "{'loss': tensor(0.2294, device='cuda:0'), 'train_macro_f1': 0.9444444444444444, 'train_macro_f1_author': 0.8888888888888888}\n",
      "{'loss': tensor(0.2136, device='cuda:0'), 'train_macro_f1': 0.9384164222873901, 'train_macro_f1_author': 0.9090909090909091}\n",
      "{'loss': tensor(0.2933, device='cuda:0'), 'train_macro_f1': 0.8636363636363636, 'train_macro_f1_author': 0.7272727272727273}\n",
      "{'loss': tensor(0.1941, device='cuda:0'), 'train_macro_f1': 0.9, 'train_macro_f1_author': 0.8}\n",
      "{'loss': tensor(0.2195, device='cuda:0'), 'train_macro_f1': 0.9583333333333333, 'train_macro_f1_author': 0.9166666666666666}\n",
      "{'loss': tensor(0.1331, device='cuda:0'), 'train_macro_f1': 0.9166666666666667, 'train_macro_f1_author': 0.8333333333333334}\n",
      "{'loss': tensor(0.2409, device='cuda:0'), 'train_macro_f1': 0.8529411764705883, 'train_macro_f1_author': 0.7058823529411765}\n",
      "{'loss': tensor(0.2663, device='cuda:0'), 'train_macro_f1': 0.9444444444444444, 'train_macro_f1_author': 0.8888888888888888}\n",
      "{'loss': tensor(0.2543, device='cuda:0'), 'train_macro_f1': 0.9230769230769231, 'train_macro_f1_author': 0.8461538461538461}\n",
      "{'loss': tensor(0.2803, device='cuda:0'), 'train_macro_f1': 0.9384164222873901, 'train_macro_f1_author': 0.9090909090909091}\n",
      "{'loss': tensor(0.3159, device='cuda:0'), 'train_macro_f1': 0.8809523809523809, 'train_macro_f1_author': 0.7619047619047619}\n",
      "{'loss': tensor(0.2997, device='cuda:0'), 'train_macro_f1': 0.8929618768328447, 'train_macro_f1_author': 0.8181818181818182}\n",
      "{'loss': tensor(0.2504, device='cuda:0'), 'train_macro_f1': 0.8956356736242884, 'train_macro_f1_author': 0.8235294117647058}\n",
      "{'loss': tensor(0.2635, device='cuda:0'), 'train_macro_f1': 0.9, 'train_macro_f1_author': 0.8}\n",
      "{'loss': tensor(0.3601, device='cuda:0'), 'train_macro_f1': 0.8157894736842105, 'train_macro_f1_author': 0.631578947368421}\n",
      "{'loss': tensor(0.2268, device='cuda:0'), 'train_macro_f1': 0.9666666666666667, 'train_macro_f1_author': 0.9333333333333333}\n",
      "{'loss': tensor(0.1810, device='cuda:0'), 'train_macro_f1': 0.9705882352941176, 'train_macro_f1_author': 0.9411764705882353}\n",
      "{'loss': tensor(0.2001, device='cuda:0'), 'train_macro_f1': 0.9583333333333333, 'train_macro_f1_author': 0.9166666666666666}\n",
      "{'loss': tensor(0.3185, device='cuda:0'), 'train_macro_f1': 0.9005376344086022, 'train_macro_f1_author': 0.8333333333333334}\n",
      "{'loss': tensor(0.2212, device='cuda:0'), 'train_macro_f1': 0.9210526315789473, 'train_macro_f1_author': 0.8421052631578947}\n",
      "{'loss': tensor(0.2195, device='cuda:0'), 'train_macro_f1': 0.8076923076923077, 'train_macro_f1_author': 0.6153846153846154}\n",
      "{'loss': tensor(0.2294, device='cuda:0'), 'train_macro_f1': 0.94, 'train_macro_f1_author': 0.88}\n",
      "{'loss': tensor(0.1932, device='cuda:0'), 'train_macro_f1': 0.9090909090909092, 'train_macro_f1_author': 0.8181818181818182}\n",
      "{'loss': tensor(0.1602, device='cuda:0'), 'train_macro_f1': 0.9444444444444444, 'train_macro_f1_author': 0.8888888888888888}\n",
      "{'loss': tensor(0.3041, device='cuda:0'), 'train_macro_f1': 0.9, 'train_macro_f1_author': 0.8}\n",
      "{'loss': tensor(0.2871, device='cuda:0'), 'train_macro_f1': 0.9481566820276498, 'train_macro_f1_author': 0.9285714285714286}\n",
      "{'loss': tensor(0.2087, device='cuda:0'), 'train_macro_f1': 0.8888888888888888, 'train_macro_f1_author': 0.7777777777777778}\n",
      "{'loss': tensor(0.2773, device='cuda:0'), 'train_macro_f1': 0.8809523809523809, 'train_macro_f1_author': 0.7619047619047619}\n",
      "{'loss': tensor(0.2917, device='cuda:0'), 'train_macro_f1': 0.9285714285714286, 'train_macro_f1_author': 0.8571428571428571}\n",
      "{'loss': tensor(0.3247, device='cuda:0'), 'train_macro_f1': 0.8838709677419355, 'train_macro_f1_author': 0.8}\n",
      "{'loss': tensor(0.2112, device='cuda:0'), 'train_macro_f1': 1.0, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.2205, device='cuda:0'), 'train_macro_f1': 0.8529411764705883, 'train_macro_f1_author': 0.7058823529411765}\n",
      "{'loss': tensor(0.2301, device='cuda:0'), 'train_macro_f1': 0.8571428571428572, 'train_macro_f1_author': 0.7142857142857143}\n",
      "{'loss': tensor(0.3261, device='cuda:0'), 'train_macro_f1': 0.8727598566308243, 'train_macro_f1_author': 0.7777777777777778}\n",
      "{'loss': tensor(0.2318, device='cuda:0'), 'train_macro_f1': 0.8956356736242884, 'train_macro_f1_author': 0.8235294117647058}\n",
      "{'loss': tensor(0.2042, device='cuda:0'), 'train_macro_f1': 0.9347826086956521, 'train_macro_f1_author': 0.8695652173913043}\n",
      "{'loss': tensor(0.2536, device='cuda:0'), 'train_macro_f1': 0.8956356736242884, 'train_macro_f1_author': 0.8235294117647058}\n",
      "{'loss': tensor(0.2279, device='cuda:0'), 'train_macro_f1': 0.9210526315789473, 'train_macro_f1_author': 0.8421052631578947}\n",
      "{'loss': tensor(0.2554, device='cuda:0'), 'train_macro_f1': 0.9210526315789473, 'train_macro_f1_author': 0.8421052631578947}\n",
      "{'loss': tensor(0.2748, device='cuda:0'), 'train_macro_f1': 0.9090909090909092, 'train_macro_f1_author': 0.8181818181818182}\n",
      "{'loss': tensor(0.4438, device='cuda:0'), 'train_macro_f1': 0.8172043010752688, 'train_macro_f1_author': 0.6666666666666666}\n",
      "{'loss': tensor(0.2968, device='cuda:0'), 'train_macro_f1': 0.9117647058823529, 'train_macro_f1_author': 0.8235294117647058}\n",
      "{'loss': tensor(0.1280, device='cuda:0'), 'train_macro_f1': 0.9444444444444444, 'train_macro_f1_author': 0.8888888888888888}\n",
      "{'loss': tensor(0.2208, device='cuda:0'), 'train_macro_f1': 0.9600614439324117, 'train_macro_f1_author': 0.9523809523809523}\n",
      "{'loss': tensor(0.2283, device='cuda:0'), 'train_macro_f1': 0.8888888888888888, 'train_macro_f1_author': 0.7777777777777778}\n",
      "{'loss': tensor(0.2726, device='cuda:0'), 'train_macro_f1': 0.9285714285714286, 'train_macro_f1_author': 0.8571428571428571}\n",
      "{'loss': tensor(0.2304, device='cuda:0'), 'train_macro_f1': 0.9544592030360531, 'train_macro_f1_author': 0.9411764705882353}\n",
      "{'loss': tensor(0.3227, device='cuda:0'), 'train_macro_f1': 0.8636363636363636, 'train_macro_f1_author': 0.7272727272727273}\n",
      "{'loss': tensor(0.1480, device='cuda:0'), 'train_macro_f1': 1.0, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.2756, device='cuda:0'), 'train_macro_f1': 0.9575551782682512, 'train_macro_f1_author': 0.9473684210526315}\n",
      "{'loss': tensor(0.2130, device='cuda:0'), 'train_macro_f1': 1.0, 'train_macro_f1_author': 1.0}\n",
      "{'loss': tensor(0.1532, device='cuda:0'), 'train_macro_f1': 0.9736842105263157, 'train_macro_f1_author': 0.9473684210526315}\n",
      "{'loss': tensor(0.2642, device='cuda:0'), 'train_macro_f1': 0.875, 'train_macro_f1_author': 0.75}\n",
      "{'loss': tensor(0.2145, device='cuda:0'), 'train_macro_f1': 0.9583333333333333, 'train_macro_f1_author': 0.9166666666666666}\n",
      "{'loss': tensor(0.3168, device='cuda:0'), 'train_macro_f1': 0.8727598566308243, 'train_macro_f1_author': 0.7777777777777778}\n",
      "{'loss': tensor(0.2505, device='cuda:0'), 'train_macro_f1': 0.8571428571428572, 'train_macro_f1_author': 0.7142857142857143}\n",
      "{'loss': tensor(0.2225, device='cuda:0'), 'train_macro_f1': 0.9482758620689655, 'train_macro_f1_author': 0.896551724137931}\n",
      "{'loss': tensor(0.1982, device='cuda:0'), 'train_macro_f1': 0.9347826086956521, 'train_macro_f1_author': 0.8695652173913043}\n",
      "{'loss': tensor(0.2601, device='cuda:0'), 'train_macro_f1': 0.8888888888888888, 'train_macro_f1_author': 0.7777777777777778}\n",
      "Overall Results\n",
      "{'epoch': 1, 'loss': 0.26011547446250916, 'val_f1_macro': 0.9159366262814539, 'val_f1_micro': 0.9335548172757475, 'val_f1_author': 0.8390804597701149}\n",
      "{'loss': tensor(0.3951, device='cuda:0'), 'train_macro_f1': 0.8172043010752688, 'train_macro_f1_author': 0.6666666666666666}\n",
      "{'loss': tensor(0.4359, device='cuda:0'), 'train_macro_f1': 0.8, 'train_macro_f1_author': 0.6}\n",
      "{'loss': tensor(0.3810, device='cuda:0'), 'train_macro_f1': 0.7666666666666666, 'train_macro_f1_author': 0.5333333333333333}\n",
      "{'loss': tensor(0.4357, device='cuda:0'), 'train_macro_f1': 0.8333333333333333, 'train_macro_f1_author': 0.6666666666666666}\n",
      "{'loss': tensor(0.3810, device='cuda:0'), 'train_macro_f1': 0.8157894736842105, 'train_macro_f1_author': 0.631578947368421}\n",
      "{'loss': tensor(0.3769, device='cuda:0'), 'train_macro_f1': 0.7941176470588236, 'train_macro_f1_author': 0.5882352941176471}\n",
      "{'loss': tensor(0.3628, device='cuda:0'), 'train_macro_f1': 0.7352941176470589, 'train_macro_f1_author': 0.47058823529411764}\n",
      "{'loss': tensor(0.3874, device='cuda:0'), 'train_macro_f1': 0.7779886148007591, 'train_macro_f1_author': 0.5882352941176471}\n",
      "{'loss': tensor(0.4098, device='cuda:0'), 'train_macro_f1': 0.7941176470588236, 'train_macro_f1_author': 0.5882352941176471}\n",
      "{'loss': tensor(0.4303, device='cuda:0'), 'train_macro_f1': 0.7352941176470589, 'train_macro_f1_author': 0.47058823529411764}\n",
      "{'loss': tensor(0.3251, device='cuda:0'), 'train_macro_f1': 0.8529411764705883, 'train_macro_f1_author': 0.7058823529411765}\n",
      "{'loss': tensor(0.4011, device='cuda:0'), 'train_macro_f1': 0.9, 'train_macro_f1_author': 0.8}\n",
      "{'loss': tensor(0.3647, device='cuda:0'), 'train_macro_f1': 0.8648233486943164, 'train_macro_f1_author': 0.7619047619047619}\n",
      "{'loss': tensor(0.3154, device='cuda:0'), 'train_macro_f1': 0.9210526315789473, 'train_macro_f1_author': 0.8421052631578947}\n",
      "{'loss': tensor(0.3639, device='cuda:0'), 'train_macro_f1': 0.7777777777777778, 'train_macro_f1_author': 0.5555555555555556}\n",
      "{'loss': tensor(0.3342, device='cuda:0'), 'train_macro_f1': 0.8888888888888888, 'train_macro_f1_author': 0.7777777777777778}\n",
      "{'loss': tensor(0.3577, device='cuda:0'), 'train_macro_f1': 0.8636363636363636, 'train_macro_f1_author': 0.7272727272727273}\n",
      "{'loss': tensor(0.3783, device='cuda:0'), 'train_macro_f1': 0.7941176470588236, 'train_macro_f1_author': 0.5882352941176471}\n",
      "{'loss': tensor(0.3814, device='cuda:0'), 'train_macro_f1': 0.8181818181818181, 'train_macro_f1_author': 0.6363636363636364}\n",
      "{'loss': tensor(0.3523, device='cuda:0'), 'train_macro_f1': 0.85, 'train_macro_f1_author': 0.7}\n",
      "{'loss': tensor(0.3998, device='cuda:0'), 'train_macro_f1': 0.8172043010752688, 'train_macro_f1_author': 0.6666666666666666}\n",
      "{'loss': tensor(0.3674, device='cuda:0'), 'train_macro_f1': 0.85, 'train_macro_f1_author': 0.7}\n",
      "{'loss': tensor(0.3921, device='cuda:0'), 'train_macro_f1': 0.875, 'train_macro_f1_author': 0.75}\n",
      "{'loss': tensor(0.3565, device='cuda:0'), 'train_macro_f1': 0.8636363636363636, 'train_macro_f1_author': 0.7272727272727273}\n",
      "{'loss': tensor(0.3491, device='cuda:0'), 'train_macro_f1': 0.8888888888888888, 'train_macro_f1_author': 0.7777777777777778}\n",
      "{'loss': tensor(0.3952, device='cuda:0'), 'train_macro_f1': 0.85, 'train_macro_f1_author': 0.7}\n",
      "{'loss': tensor(0.4214, device='cuda:0'), 'train_macro_f1': 0.75, 'train_macro_f1_author': 0.5}\n",
      "{'loss': tensor(0.3929, device='cuda:0'), 'train_macro_f1': 0.7777777777777778, 'train_macro_f1_author': 0.5555555555555556}\n",
      "{'loss': tensor(0.4292, device='cuda:0'), 'train_macro_f1': 0.7, 'train_macro_f1_author': 0.4}\n",
      "{'loss': tensor(0.3468, device='cuda:0'), 'train_macro_f1': 0.8888888888888888, 'train_macro_f1_author': 0.7777777777777778}\n",
      "{'loss': tensor(0.3947, device='cuda:0'), 'train_macro_f1': 0.9, 'train_macro_f1_author': 0.8}\n",
      "{'loss': tensor(0.3210, device='cuda:0'), 'train_macro_f1': 0.9285714285714286, 'train_macro_f1_author': 0.8571428571428571}\n",
      "{'loss': tensor(0.3187, device='cuda:0'), 'train_macro_f1': 0.9545454545454546, 'train_macro_f1_author': 0.9090909090909091}\n",
      "{'loss': tensor(0.3760, device='cuda:0'), 'train_macro_f1': 0.8125, 'train_macro_f1_author': 0.625}\n",
      "{'loss': tensor(0.3781, device='cuda:0'), 'train_macro_f1': 0.9285714285714286, 'train_macro_f1_author': 0.8571428571428571}\n",
      "{'loss': tensor(0.3754, device='cuda:0'), 'train_macro_f1': 0.8125, 'train_macro_f1_author': 0.625}\n",
      "{'loss': tensor(0.3563, device='cuda:0'), 'train_macro_f1': 0.8125, 'train_macro_f1_author': 0.625}\n",
      "{'loss': tensor(0.4105, device='cuda:0'), 'train_macro_f1': 0.8478260869565217, 'train_macro_f1_author': 0.6956521739130435}\n",
      "{'loss': tensor(0.4156, device='cuda:0'), 'train_macro_f1': 0.7838709677419355, 'train_macro_f1_author': 0.6}\n",
      "{'loss': tensor(0.4479, device='cuda:0'), 'train_macro_f1': 0.8172043010752688, 'train_macro_f1_author': 0.6666666666666666}\n",
      "{'loss': tensor(0.3745, device='cuda:0'), 'train_macro_f1': 0.8333333333333333, 'train_macro_f1_author': 0.6666666666666666}\n",
      "{'loss': tensor(0.3881, device='cuda:0'), 'train_macro_f1': 0.85, 'train_macro_f1_author': 0.7}\n",
      "{'loss': tensor(0.3632, device='cuda:0'), 'train_macro_f1': 0.7777777777777778, 'train_macro_f1_author': 0.5555555555555556}\n",
      "{'loss': tensor(0.3209, device='cuda:0'), 'train_macro_f1': 0.9210526315789473, 'train_macro_f1_author': 0.8421052631578947}\n",
      "{'loss': tensor(0.3491, device='cuda:0'), 'train_macro_f1': 0.8333333333333333, 'train_macro_f1_author': 0.6666666666666666}\n",
      "{'loss': tensor(0.4486, device='cuda:0'), 'train_macro_f1': 0.7191650853889944, 'train_macro_f1_author': 0.47058823529411764}\n",
      "{'loss': tensor(0.3894, device='cuda:0'), 'train_macro_f1': 0.7777777777777778, 'train_macro_f1_author': 0.5555555555555556}\n",
      "{'loss': tensor(0.3338, device='cuda:0'), 'train_macro_f1': 0.868421052631579, 'train_macro_f1_author': 0.7368421052631579}\n",
      "{'loss': tensor(0.3507, device='cuda:0'), 'train_macro_f1': 0.7963709677419355, 'train_macro_f1_author': 0.625}\n",
      "{'loss': tensor(0.3629, device='cuda:0'), 'train_macro_f1': 0.7857142857142857, 'train_macro_f1_author': 0.5714285714285714}\n",
      "{'loss': tensor(0.3810, device='cuda:0'), 'train_macro_f1': 0.8043478260869565, 'train_macro_f1_author': 0.6086956521739131}\n",
      "{'loss': tensor(0.3590, device='cuda:0'), 'train_macro_f1': 0.9212121212121211, 'train_macro_f1_author': 0.9090909090909091}\n",
      "{'loss': tensor(0.3687, device='cuda:0'), 'train_macro_f1': 0.9124423963133641, 'train_macro_f1_author': 0.8571428571428571}\n",
      "{'loss': tensor(0.3571, device='cuda:0'), 'train_macro_f1': 0.8913043478260869, 'train_macro_f1_author': 0.782608695652174}\n",
      "{'loss': tensor(0.3014, device='cuda:0'), 'train_macro_f1': 0.9444444444444444, 'train_macro_f1_author': 0.8888888888888888}\n",
      "{'loss': tensor(0.3501, device='cuda:0'), 'train_macro_f1': 0.9583333333333333, 'train_macro_f1_author': 0.9166666666666666}\n",
      "{'loss': tensor(0.3577, device='cuda:0'), 'train_macro_f1': 0.9583333333333333, 'train_macro_f1_author': 0.9166666666666666}\n",
      "{'loss': tensor(0.3662, device='cuda:0'), 'train_macro_f1': 0.75, 'train_macro_f1_author': 0.5}\n",
      "{'loss': tensor(0.3256, device='cuda:0'), 'train_macro_f1': 0.8888888888888888, 'train_macro_f1_author': 0.7777777777777778}\n",
      "{'loss': tensor(0.4106, device='cuda:0'), 'train_macro_f1': 0.85, 'train_macro_f1_author': 0.7}\n",
      "{'loss': tensor(0.3289, device='cuda:0'), 'train_macro_f1': 0.9210526315789473, 'train_macro_f1_author': 0.8421052631578947}\n",
      "{'loss': tensor(0.3956, device='cuda:0'), 'train_macro_f1': 0.8125, 'train_macro_f1_author': 0.625}\n",
      "{'loss': tensor(0.3416, device='cuda:0'), 'train_macro_f1': 0.8636363636363636, 'train_macro_f1_author': 0.7272727272727273}\n",
      "{'loss': tensor(0.3535, device='cuda:0'), 'train_macro_f1': 0.868421052631579, 'train_macro_f1_author': 0.7368421052631579}\n",
      "{'loss': tensor(0.3405, device='cuda:0'), 'train_macro_f1': 0.8125, 'train_macro_f1_author': 0.625}\n",
      "{'loss': tensor(0.4473, device='cuda:0'), 'train_macro_f1': 0.8333333333333333, 'train_macro_f1_author': 0.6666666666666666}\n",
      "{'loss': tensor(0.3301, device='cuda:0'), 'train_macro_f1': 0.9090909090909092, 'train_macro_f1_author': 0.8181818181818182}\n",
      "{'loss': tensor(0.4312, device='cuda:0'), 'train_macro_f1': 0.7777777777777778, 'train_macro_f1_author': 0.5555555555555556}\n",
      "{'loss': tensor(0.3329, device='cuda:0'), 'train_macro_f1': 0.8529411764705883, 'train_macro_f1_author': 0.7058823529411765}\n",
      "{'loss': tensor(0.3077, device='cuda:0'), 'train_macro_f1': 0.8333333333333333, 'train_macro_f1_author': 0.6666666666666666}\n",
      "{'loss': tensor(0.3527, device='cuda:0'), 'train_macro_f1': 0.7695852534562212, 'train_macro_f1_author': 0.5714285714285714}\n",
      "{'loss': tensor(0.3591, device='cuda:0'), 'train_macro_f1': 0.8636363636363636, 'train_macro_f1_author': 0.7272727272727273}\n",
      "{'loss': tensor(0.3767, device='cuda:0'), 'train_macro_f1': 0.8636363636363636, 'train_macro_f1_author': 0.7272727272727273}\n",
      "{'loss': tensor(0.4177, device='cuda:0'), 'train_macro_f1': 0.8181818181818181, 'train_macro_f1_author': 0.6363636363636364}\n",
      "{'loss': tensor(0.4227, device='cuda:0'), 'train_macro_f1': 0.7857142857142857, 'train_macro_f1_author': 0.5714285714285714}\n",
      "{'loss': tensor(0.3951, device='cuda:0'), 'train_macro_f1': 0.8181818181818181, 'train_macro_f1_author': 0.6363636363636364}\n",
      "{'loss': tensor(0.4122, device='cuda:0'), 'train_macro_f1': 0.8333333333333333, 'train_macro_f1_author': 0.6666666666666666}\n",
      "{'loss': tensor(0.3746, device='cuda:0'), 'train_macro_f1': 0.8636363636363636, 'train_macro_f1_author': 0.7272727272727273}\n",
      "{'loss': tensor(0.3388, device='cuda:0'), 'train_macro_f1': 0.8529411764705883, 'train_macro_f1_author': 0.7058823529411765}\n",
      "{'loss': tensor(0.3330, device='cuda:0'), 'train_macro_f1': 0.9583333333333333, 'train_macro_f1_author': 0.9166666666666666}\n",
      "{'loss': tensor(0.3954, device='cuda:0'), 'train_macro_f1': 0.8588709677419355, 'train_macro_f1_author': 0.75}\n",
      "{'loss': tensor(0.3640, device='cuda:0'), 'train_macro_f1': 0.9090909090909092, 'train_macro_f1_author': 0.8181818181818182}\n",
      "{'loss': tensor(0.3913, device='cuda:0'), 'train_macro_f1': 0.868421052631579, 'train_macro_f1_author': 0.7368421052631579}\n",
      "{'loss': tensor(0.3640, device='cuda:0'), 'train_macro_f1': 0.7142857142857143, 'train_macro_f1_author': 0.42857142857142855}\n",
      "{'loss': tensor(0.3475, device='cuda:0'), 'train_macro_f1': 0.8913043478260869, 'train_macro_f1_author': 0.782608695652174}\n",
      "{'loss': tensor(0.3383, device='cuda:0'), 'train_macro_f1': 0.8888888888888888, 'train_macro_f1_author': 0.7777777777777778}\n",
      "{'loss': tensor(0.3334, device='cuda:0'), 'train_macro_f1': 0.85, 'train_macro_f1_author': 0.7}\n",
      "{'loss': tensor(0.3160, device='cuda:0'), 'train_macro_f1': 0.9285714285714286, 'train_macro_f1_author': 0.8571428571428571}\n",
      "{'loss': tensor(0.4096, device='cuda:0'), 'train_macro_f1': 0.763157894736842, 'train_macro_f1_author': 0.5263157894736842}\n",
      "{'loss': tensor(0.4073, device='cuda:0'), 'train_macro_f1': 0.7941176470588236, 'train_macro_f1_author': 0.5882352941176471}\n",
      "{'loss': tensor(0.3309, device='cuda:0'), 'train_macro_f1': 0.8888888888888888, 'train_macro_f1_author': 0.7777777777777778}\n",
      "{'loss': tensor(0.3499, device='cuda:0'), 'train_macro_f1': 0.7857142857142857, 'train_macro_f1_author': 0.5714285714285714}\n",
      "{'loss': tensor(0.4040, device='cuda:0'), 'train_macro_f1': 0.7222222222222222, 'train_macro_f1_author': 0.4444444444444444}\n",
      "{'loss': tensor(0.3248, device='cuda:0'), 'train_macro_f1': 0.8333333333333333, 'train_macro_f1_author': 0.6666666666666666}\n",
      "{'loss': tensor(0.3753, device='cuda:0'), 'train_macro_f1': 0.868421052631579, 'train_macro_f1_author': 0.7368421052631579}\n",
      "{'loss': tensor(0.3479, device='cuda:0'), 'train_macro_f1': 0.8846153846153846, 'train_macro_f1_author': 0.7692307692307693}\n",
      "{'loss': tensor(0.3410, device='cuda:0'), 'train_macro_f1': 0.9, 'train_macro_f1_author': 0.8}\n",
      "{'loss': tensor(0.3963, device='cuda:0'), 'train_macro_f1': 0.8157894736842105, 'train_macro_f1_author': 0.631578947368421}\n",
      "{'loss': tensor(0.3574, device='cuda:0'), 'train_macro_f1': 0.8809523809523809, 'train_macro_f1_author': 0.7619047619047619}\n",
      "{'loss': tensor(0.3861, device='cuda:0'), 'train_macro_f1': 0.8157894736842105, 'train_macro_f1_author': 0.631578947368421}\n",
      "{'loss': tensor(0.3814, device='cuda:0'), 'train_macro_f1': 0.7941176470588236, 'train_macro_f1_author': 0.5882352941176471}\n",
      "{'loss': tensor(0.4488, device='cuda:0'), 'train_macro_f1': 0.7191650853889944, 'train_macro_f1_author': 0.47058823529411764}\n",
      "{'loss': tensor(0.3653, device='cuda:0'), 'train_macro_f1': 0.8, 'train_macro_f1_author': 0.6}\n",
      "{'loss': tensor(0.3800, device='cuda:0'), 'train_macro_f1': 0.9090909090909092, 'train_macro_f1_author': 0.8181818181818182}\n",
      "{'loss': tensor(0.4501, device='cuda:0'), 'train_macro_f1': 0.7, 'train_macro_f1_author': 0.4}\n",
      "{'loss': tensor(0.3716, device='cuda:0'), 'train_macro_f1': 0.8157894736842105, 'train_macro_f1_author': 0.631578947368421}\n",
      "{'loss': tensor(0.4077, device='cuda:0'), 'train_macro_f1': 0.8125, 'train_macro_f1_author': 0.625}\n",
      "{'loss': tensor(0.3427, device='cuda:0'), 'train_macro_f1': 0.85, 'train_macro_f1_author': 0.7}\n",
      "{'loss': tensor(0.4211, device='cuda:0'), 'train_macro_f1': 0.75, 'train_macro_f1_author': 0.5}\n",
      "{'loss': tensor(0.4304, device='cuda:0'), 'train_macro_f1': 0.8125, 'train_macro_f1_author': 0.625}\n",
      "{'loss': tensor(0.3699, device='cuda:0'), 'train_macro_f1': 0.8888888888888888, 'train_macro_f1_author': 0.7777777777777778}\n",
      "{'loss': tensor(0.3924, device='cuda:0'), 'train_macro_f1': 0.8757575757575757, 'train_macro_f1_author': 0.8181818181818182}\n",
      "{'loss': tensor(0.3401, device='cuda:0'), 'train_macro_f1': 0.9, 'train_macro_f1_author': 0.8}\n",
      "{'loss': tensor(0.3716, device='cuda:0'), 'train_macro_f1': 0.8125, 'train_macro_f1_author': 0.625}\n",
      "{'loss': tensor(0.4075, device='cuda:0'), 'train_macro_f1': 0.7352941176470589, 'train_macro_f1_author': 0.47058823529411764}\n",
      "{'loss': tensor(0.3608, device='cuda:0'), 'train_macro_f1': 0.868421052631579, 'train_macro_f1_author': 0.7368421052631579}\n",
      "{'loss': tensor(0.3984, device='cuda:0'), 'train_macro_f1': 0.7, 'train_macro_f1_author': 0.4}\n",
      "{'loss': tensor(0.3918, device='cuda:0'), 'train_macro_f1': 0.8333333333333333, 'train_macro_f1_author': 0.6666666666666666}\n",
      "{'loss': tensor(0.3362, device='cuda:0'), 'train_macro_f1': 0.9, 'train_macro_f1_author': 0.8}\n",
      "{'loss': tensor(0.4851, device='cuda:0'), 'train_macro_f1': 0.7219662058371736, 'train_macro_f1_author': 0.47619047619047616}\n",
      "{'loss': tensor(0.3989, device='cuda:0'), 'train_macro_f1': 0.8333333333333333, 'train_macro_f1_author': 0.6666666666666666}\n",
      "{'loss': tensor(0.3119, device='cuda:0'), 'train_macro_f1': 0.8125, 'train_macro_f1_author': 0.625}\n",
      "{'loss': tensor(0.3339, device='cuda:0'), 'train_macro_f1': 0.9, 'train_macro_f1_author': 0.8}\n",
      "{'loss': tensor(0.4001, device='cuda:0'), 'train_macro_f1': 0.8, 'train_macro_f1_author': 0.6}\n",
      "{'loss': tensor(0.3429, device='cuda:0'), 'train_macro_f1': 0.868421052631579, 'train_macro_f1_author': 0.7368421052631579}\n",
      "{'loss': tensor(0.3707, device='cuda:0'), 'train_macro_f1': 0.8571428571428572, 'train_macro_f1_author': 0.7142857142857143}\n",
      "{'loss': tensor(0.3437, device='cuda:0'), 'train_macro_f1': 0.7777777777777778, 'train_macro_f1_author': 0.5555555555555556}\n",
      "{'loss': tensor(0.3909, device='cuda:0'), 'train_macro_f1': 0.8333333333333333, 'train_macro_f1_author': 0.6666666666666666}\n",
      "{'loss': tensor(0.3630, device='cuda:0'), 'train_macro_f1': 0.8157894736842105, 'train_macro_f1_author': 0.631578947368421}\n",
      "{'loss': tensor(0.3919, device='cuda:0'), 'train_macro_f1': 0.8333333333333333, 'train_macro_f1_author': 0.6666666666666666}\n",
      "{'loss': tensor(0.4095, device='cuda:0'), 'train_macro_f1': 0.7666666666666666, 'train_macro_f1_author': 0.5333333333333333}\n",
      "{'loss': tensor(0.3579, device='cuda:0'), 'train_macro_f1': 0.9166666666666667, 'train_macro_f1_author': 0.8333333333333334}\n",
      "{'loss': tensor(0.3845, device='cuda:0'), 'train_macro_f1': 0.7142857142857143, 'train_macro_f1_author': 0.42857142857142855}\n",
      "{'loss': tensor(0.3504, device='cuda:0'), 'train_macro_f1': 0.8838709677419355, 'train_macro_f1_author': 0.8}\n",
      "{'loss': tensor(0.3684, device='cuda:0'), 'train_macro_f1': 0.8076923076923077, 'train_macro_f1_author': 0.6153846153846154}\n",
      "{'loss': tensor(0.3614, device='cuda:0'), 'train_macro_f1': 0.8727598566308243, 'train_macro_f1_author': 0.7777777777777778}\n",
      "{'loss': tensor(0.5205, device='cuda:0'), 'train_macro_f1': 0.7838709677419355, 'train_macro_f1_author': 0.6}\n",
      "{'loss': tensor(0.3578, device='cuda:0'), 'train_macro_f1': 0.7666666666666666, 'train_macro_f1_author': 0.5333333333333333}\n",
      "{'loss': tensor(0.3861, device='cuda:0'), 'train_macro_f1': 0.7727272727272727, 'train_macro_f1_author': 0.5454545454545454}\n",
      "{'loss': tensor(0.3571, device='cuda:0'), 'train_macro_f1': 0.9117647058823529, 'train_macro_f1_author': 0.8235294117647058}\n",
      "Overall Results\n",
      "{'epoch': 1, 'loss': 0.35706958174705505, 'val_f1_macro': 0.8391802221504172, 'val_f1_micro': 0.8792325056433409, 'val_f1_author': 0.6828528072837633}\n"
     ]
    }
   ],
   "source": [
    "# get DataLoader\n",
    "test_loader = DataLoader(ds['test_0'], batch_size=batch_size, collate_fn=collate_fn)\n",
    "test_model(test_loader)\n",
    "\n",
    "test_loader = DataLoader(ds['test_1'], batch_size=batch_size, collate_fn=collate_fn)\n",
    "test_model(test_loader)\n",
    "\n",
    "test_loader = DataLoader(ds['test_2'], batch_size=batch_size, collate_fn=collate_fn)\n",
    "test_model(test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bbed18-ebf5-4063-b76c-1de844ccc403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get DataLoader\n",
    "test_loader = DataLoader(ds['test_0'], batch_size=batch_size, collate_fn=collate_fn)\n",
    "test_model(test_loader)\n",
    "\n",
    "test_loader = DataLoader(ds['test_1'], batch_size=batch_size, collate_fn=collate_fn)\n",
    "test_model(test_loader)\n",
    "\n",
    "test_loader = DataLoader(ds['test_2'], batch_size=batch_size, collate_fn=collate_fn)\n",
    "test_model(test_loader)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
