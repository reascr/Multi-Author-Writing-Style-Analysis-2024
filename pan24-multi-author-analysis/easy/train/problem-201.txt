Now, in the case the Court will decide, the Section 230 issue isn't that there was content that incited immediate violence (which wouldn't have been a legal problem for the website), the issue is that the website's algorithm actively promoted that content to some of its users. So now that's no longer just user generated content, but website generated promotion of content inciting violence, and that's a liability issue for the website now, which the Court will probably hold isn't covered under Section 230.
And I’m not as convinced as you are. The input to those algorithms is: information provided by the current user (previous views, demographic information etc) and the content available. As much as conspiracy theories like to speculate that there’s a “finger on the scale” to tip it one way or another, there generally isn’t. Otherwise Musk would be shouting about it constantly right now. It’s a meat grinder (probably not the best analogy given Ukraine right now but it’s what my brain came up with) and the algorithm is the grinder plate. What comes out is all based on what went into it. It’s all just meat.