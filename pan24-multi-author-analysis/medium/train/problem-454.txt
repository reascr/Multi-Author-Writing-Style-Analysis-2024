I've lived in Florida my whole life, seen first-hand the changes that have gone on the last 10 years or so. This state is done. The people here have become hateful, disgusting bigots. None of this is going to do anything. Almost everyone here supports the cruelty and the bigoted policies. They love it. Best thing these kids can do is leave, go to a state that has decent human beings and don't look back. And anyone outside of Florida that wants to do something, don't come here. This state relies on tourism. Don't spend your money here propping up this hateful state. Go to California instead. They have Disney and beaches.
In general, be courteous to others. Debate/discuss/argue the merits of ideas, don't attack people. Personal insults, shill or troll accusations, hate speech, any suggestion or support of harm, violence, or death, and other rule violations can result in a permanent ban.
For those who have questions regarding any media outlets being posted on this subreddit, please click to review our details as to our approved domains list and outlet criteria.