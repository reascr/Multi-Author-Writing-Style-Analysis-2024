{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb4e23d3",
   "metadata": {},
   "source": [
    "### Data Augmentation and Oversampling\n",
    "\n",
    "The idea is to leverage the metadata and to follow the algorithm proposed by Hashemi et al. (2023) to get pairs of non-consecutive paragraphs (with and\n",
    "without style changes). Then, classes will be oversampled to obtain a balanced data set.\n",
    "\n",
    "Description of the algorithm: \" incorporate additional non-consecutive pairs of paragraphs\n",
    "into our sample set and assign them labels based on the inferred relationships. For example, if\n",
    "there are three consecutive paragraphs without a style change, we can infer that the first and\n",
    "third paragraphs are written by the same author. Similarly, if there are style changes between\n",
    "the first and second paragraphs and between the second and third paragraphs, we can deduce\n",
    "that the authors of the first and third paragraphs are different, given that the number of authors\n",
    "in the document exceeds the number of style changes by one.\" (Hashemi et al. 2023: 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61d49e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e43bf86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where label_author == 0 (training data): 20485\n",
      "Number of rows where label_author == 1 (training data): 31508\n",
      "Number of rows where label_author == 0 (validation data): 4489\n",
      "Number of rows where label_author == 1 (validation data): 6709\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = '../data_pipeline/'\n",
    "\n",
    "# get data sets \n",
    "df_train = pd.read_csv(os.path.join(BASE_DIR, \"df_train.csv\"))\n",
    "df_val = pd.read_csv(os.path.join(BASE_DIR, \"df_validation.csv\"))\n",
    "\n",
    "# check distribution of labels\n",
    "changes_train = len(df_train[df_train['label_author'] == 1])\n",
    "no_changes_train = len(df_train[df_train['label_author'] == 0])\n",
    "\n",
    "changes_val = len(df_val[df_val['label_author'] == 1])\n",
    "no_changes_val = len(df_val[df_val['label_author'] == 0])\n",
    "\n",
    "print(f\"Number of rows where label_author == 0 (training data): {no_changes_train}\")\n",
    "print(f\"Number of rows where label_author == 1 (training data): {changes_train}\")\n",
    "\n",
    "print(f\"Number of rows where label_author == 0 (validation data): {no_changes_val}\")\n",
    "print(f\"Number of rows where label_author == 1 (validation data): {changes_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50f1013e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph1</th>\n",
       "      <th>paragraph2</th>\n",
       "      <th>label_author</th>\n",
       "      <th>label_dataset</th>\n",
       "      <th>n_authors</th>\n",
       "      <th>fileindex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Look, you can believe that there was some broa...</td>\n",
       "      <td>&gt;His rambling opening statement, which lasted ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The 1028 120 mm canister may be a round the US...</td>\n",
       "      <td>Modern high explosive fragmentation weapons ex...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The 1028 120 mm canister may be a round the US...</td>\n",
       "      <td>Shrapnel shells stopped being used because the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The 1028 120 mm canister may be a round the US...</td>\n",
       "      <td>Old timey Shrapnel Shells TM worked as basical...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I just saw some videos from this attack. The m...</td>\n",
       "      <td>Shrapnel shells stopped being used because the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27087</th>\n",
       "      <td>I wonder what happens. Quatar has done so many...</td>\n",
       "      <td>In Brazil Fifa could probably sue the govt for...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27088</th>\n",
       "      <td>I wonder what happens. Quatar has done so many...</td>\n",
       "      <td>I didn't say anything about Fifa not being shi...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27089</th>\n",
       "      <td>This is FIFA. They buy/sell/own the World Cup,...</td>\n",
       "      <td>In Brazil Fifa could probably sue the govt for...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27090</th>\n",
       "      <td>This is FIFA. They buy/sell/own the World Cup,...</td>\n",
       "      <td>I didn't say anything about Fifa not being shi...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27091</th>\n",
       "      <td>Fuck you FIFA. You forced Brazil to sell it in...</td>\n",
       "      <td>I didn't say anything about Fifa not being shi...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27092 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              paragraph1  \\\n",
       "0      Look, you can believe that there was some broa...   \n",
       "1      The 1028 120 mm canister may be a round the US...   \n",
       "2      The 1028 120 mm canister may be a round the US...   \n",
       "3      The 1028 120 mm canister may be a round the US...   \n",
       "4      I just saw some videos from this attack. The m...   \n",
       "...                                                  ...   \n",
       "27087  I wonder what happens. Quatar has done so many...   \n",
       "27088  I wonder what happens. Quatar has done so many...   \n",
       "27089  This is FIFA. They buy/sell/own the World Cup,...   \n",
       "27090  This is FIFA. They buy/sell/own the World Cup,...   \n",
       "27091  Fuck you FIFA. You forced Brazil to sell it in...   \n",
       "\n",
       "                                              paragraph2  label_author  \\\n",
       "0      >His rambling opening statement, which lasted ...             1   \n",
       "1      Modern high explosive fragmentation weapons ex...             1   \n",
       "2      Shrapnel shells stopped being used because the...             1   \n",
       "3      Old timey Shrapnel Shells TM worked as basical...             1   \n",
       "4      Shrapnel shells stopped being used because the...             1   \n",
       "...                                                  ...           ...   \n",
       "27087  In Brazil Fifa could probably sue the govt for...             1   \n",
       "27088  I didn't say anything about Fifa not being shi...             1   \n",
       "27089  In Brazil Fifa could probably sue the govt for...             1   \n",
       "27090  I didn't say anything about Fifa not being shi...             1   \n",
       "27091  I didn't say anything about Fifa not being shi...             1   \n",
       "\n",
       "       label_dataset  n_authors  fileindex  \n",
       "0                  0          4         16  \n",
       "1                  0          4         19  \n",
       "2                  0          4         19  \n",
       "3                  0          4         19  \n",
       "4                  0          4         19  \n",
       "...              ...        ...        ...  \n",
       "27087              2          4       4200  \n",
       "27088              2          4       4200  \n",
       "27089              2          4       4200  \n",
       "27090              2          4       4200  \n",
       "27091              2          4       4200  \n",
       "\n",
       "[27092 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_augmentation(data):\n",
    "    augmented_rows = []\n",
    "    # problem is that fileindexes start from 1 for every label_dataset --> iterate over label_dataset first\n",
    "    unique_datasets = data['label_dataset'].unique()\n",
    "    for dataset in unique_datasets:\n",
    "        dataset_data = data[data['label_dataset'] == dataset] # get subset of data for easy, medium, and hard\n",
    "        unique_fileindexes = data['fileindex'].unique() # get unique fileindexes\n",
    "        for file_index in unique_fileindexes:\n",
    "            file_data = dataset_data[dataset_data['fileindex'] == file_index] # get DataFrame for file\n",
    "            \n",
    "            if (file_data['label_author'] == 1).sum() == (file_data[\"n_authors\"].iloc[0] - 1):\n",
    "                for i in range(len(file_data)-2):\n",
    "                    row = file_data.iloc[i]\n",
    "                    j = i + 1 # set next paragraph index\n",
    "\n",
    "                    while (j < len(file_data)) and (file_data[\"label_author\"].iloc[j-1] == 0):# while same author\n",
    "                        if j > i + 1:\n",
    "                            augmented_rows.append({\n",
    "                        'paragraph1': row['paragraph1'],\n",
    "                        'paragraph2': file_data['paragraph2'].iloc[j],\n",
    "                        'label_author': 0, # same author\n",
    "                        'label_dataset': row['label_dataset'],\n",
    "                        'n_authors': row['n_authors'],\n",
    "                        'fileindex': row['fileindex']\n",
    "                    })   \n",
    "                        j +=1 # move to next paragraph\n",
    "                    while j < len(file_data):\n",
    "                        if j > i + 1:\n",
    "                            #print(\"-----\",i,j, len(file_data))\n",
    "                            augmented_rows.append({\n",
    "                        'paragraph1': row['paragraph1'],\n",
    "                        'paragraph2': file_data['paragraph2'].iloc[j],\n",
    "                        'label_author': 1, # style change\n",
    "                        'label_dataset': row['label_dataset'],\n",
    "                        'n_authors': row['n_authors'],\n",
    "                        'fileindex': row['fileindex']\n",
    "                    })\n",
    "                        j += 1 # move to next paragraph\n",
    "            \n",
    "    # Create a new DataFrame with augmented rows\n",
    "    augmented_df = pd.DataFrame(augmented_rows)\n",
    "    #augmented_df = pd.concat([data, augmented_df], ignore_index=True)\n",
    "    return augmented_df\n",
    "\n",
    "augmented_df = data_augmentation(df_train)\n",
    "augmented_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d150558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_order(data):\n",
    "    '''double the training data by swapping paragraph1 and paragraph2'''\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
